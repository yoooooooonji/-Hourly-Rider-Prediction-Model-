{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":158,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import optuna\n","import joblib\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import font_manager\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.inspection import permutation_importance\n","import statsmodels.api as sm \n","from time import time\n","\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 한글 폰트 경로 설정\n","font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'\n","font_name = font_manager.FontProperties(fname=font_path).get_name()\n","plt.rc('font', family=font_name)"]},{"cell_type":"code","execution_count":159,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(44625, 13)\n"]}],"source":["data = pd.read_csv('combined_data.csv', encoding = \"cp949\")\n","data.head()\n","print(data.shape) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","print(data.describe())"]},{"cell_type":"code","execution_count":160,"metadata":{},"outputs":[],"source":["data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n","data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","\n","data = data.sort_values(by=\"datetime\")"]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["   pick_rgn2_nm  rider_cnt            datetime   reg_date  rider_cnt_w_1   \n","0           강남구      181.0 2023-02-01 09:00:00 2023-02-01          173.0  \\\n","24          중랑구       25.0 2023-02-01 09:00:00 2023-02-01           26.0   \n","23           중구       26.0 2023-02-01 09:00:00 2023-02-01           22.0   \n","22          종로구       23.0 2023-02-01 09:00:00 2023-02-01           19.0   \n","21          은평구       31.0 2023-02-01 09:00:00 2023-02-01           34.0   \n","\n","    rider_cnt_w_2  rider_cnt_w_3  rider_cnt_w_4  order_cnt_w_1  \n","0           178.0          178.0          194.0            380  \n","24           15.0           29.0           31.0             38  \n","23           18.0           22.0           25.0             30  \n","22           21.0           25.0           25.0             29  \n","21           30.0           34.0           31.0             63  \n"]}],"source":["data = data.drop(columns = ['holiday_yn','hour_reg','day_of_reg','rain_group'])\n","print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","#print(data.shape) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in ['pick_rgn2_nm', 'hour_reg', 'day_of_reg',  'holiday_yn' ,'rain_group'] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","# #scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# data[num_vars] = scaler.fit_transform(data[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['pick_rgn2_nm', 'rider_cnt', 'datetime', 'reg_date', 'rider_cnt_w_1',\n","       'rider_cnt_w_2', 'rider_cnt_w_3', 'rider_cnt_w_4', 'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["#df = data.drop(columns = ['is_rain','is_holiday','day_of_reg'])\n","df = data\n","# var = ['pick_rgn2_nm', 'hour_reg', 'day_of_reg', 'rain_group', 'holiday_yn']\n","# encoder = OneHotEncoder()\n","# onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","# df = pd.concat([onehot, df.drop(columns=var)], axis=1)\n","#print(df.head(3))\n","print(df.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train, test set split"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(33000, 6) (11250, 6)\n"]}],"source":["# train_ratio = 0.8\n","# total_samples = df.shape[0]\n","# train_samples = int(train_ratio * total_samples)\n","# df_train = df[:train_samples]\n","# df_test = df[train_samples:]\n","\n","df_train = df[df[\"datetime\"]<= '2023-04-30']\n","df_test = df[df[\"datetime\"] >= '2023-05-01']\n","\n","# print(df_train['reg_date'].min()) #2022-01-29\n","# print(df_test['reg_date'].min()) #2023-02-15\n","\n","# print(df_train['reg_date'].max()) #2023-02-15\n","# print(df_test['reg_date'].max()) #2023-05-21\n","\n","df_train = df_train.drop(columns = ['datetime', 'reg_date', 'pick_rgn2_nm'])\n","df_test = df_test.drop(columns = ['datetime', 'reg_date', 'pick_rgn2_nm'])\n","print(df_train.shape, df_test.shape) # 126,000, 54375 / 33000 11250 "]},{"cell_type":"code","execution_count":164,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(33000, 5) (33000,) (11250, 5) (11250,)\n"]}],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt'])\n","y_train = df_train['rider_cnt']\n","\n","X_test = df_test.drop(columns=['rider_cnt'])\n","y_test = df_test['rider_cnt']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### numeric_scale "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 입력 변수 \n","# numeric_cols = ['rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#                 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#                 'order_cnt_w_4']\n","\n","# # scaler \n","# scaler_X = StandardScaler()\n","\n","# # X_train, X_test\n","# X_train_scaled = scaler_X.fit_transform(X_train[numeric_cols])\n","# X_test_scaled = scaler_X.transform(X_test[numeric_cols])\n","\n","# # 스케일링된 결과를 DataFrame으로 변환\n","# X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_cols, index = X_train.index)\n","# X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_cols, index = X_test.index)\n","\n","# # 원래의 범주형 변수들을 선택\n","# categorical_cols = [col for col in X_train.columns if col not in numeric_cols]\n","# X_train_cat = X_train[categorical_cols]\n","# X_test_cat = X_test[categorical_cols]\n","\n","# # 스케일링된 DataFrame과 범주형 변수들을 병합\n","# X_train_final = pd.concat([X_train_scaled, X_train_cat], axis=1)\n","# X_test_final = pd.concat([X_test_scaled, X_test_cat], axis=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측값\n","# y_train, y_test\n","# scaler_y = StandardScaler()\n","# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n","# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n","# y_train_scaled = y_train_scaled.ravel()\n","# y_test_scaled=  y_test_scaled.ravel()\n","\n","# print(y_train_scaled.shape)\n","# print(y_test_scaled.shape)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":165,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:              rider_cnt   R-squared:                       0.981\n","Model:                            OLS   Adj. R-squared:                  0.981\n","Method:                 Least Squares   F-statistic:                 3.370e+05\n","Date:                Wed, 31 May 2023   Prob (F-statistic):               0.00\n","Time:                        18:02:54   Log-Likelihood:            -1.4838e+05\n","No. Observations:               33000   AIC:                         2.968e+05\n","Df Residuals:                   32994   BIC:                         2.968e+05\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","const             1.6727      0.245      6.814      0.000       1.192       2.154\n","rider_cnt_w_1     0.3735      0.006     58.043      0.000       0.361       0.386\n","rider_cnt_w_2     0.2508      0.006     43.822      0.000       0.240       0.262\n","rider_cnt_w_3     0.1705      0.006     27.991      0.000       0.159       0.182\n","rider_cnt_w_4     0.1685      0.006     28.990      0.000       0.157       0.180\n","order_cnt_w_1     0.0148      0.002      9.375      0.000       0.012       0.018\n","==============================================================================\n","Omnibus:                    15759.654   Durbin-Watson:                   1.112\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           535388.578\n","Skew:                           1.665   Prob(JB):                         0.00\n","Kurtosis:                      22.450   Cond. No.                     1.60e+03\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.6e+03. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n"]}],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 선형 회귀 모델 학습\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 잔차 계산\n","y_pred = model.predict(X_test)\n","residuals = y_test - y_pred\n","\n","# 변수별 잔차 그래프 그리기\n","for column in X_test.columns:\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x=X_test[column], y=residuals)\n","    plt.title(f'Residuals vs. {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Residuals')\n","    plt.show()\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = LGBMRegressor()\n","\n","parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","              {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","grid_search = GridSearchCV(estimator=classifier,\n","                           param_grid=parameters,\n","                           scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","                           cv=10,\n","                           n_jobs=-1,\n","                           refit='neg_mean_squared_error')                     \n","\n","grid_search.fit(X_train, y_train)\n","best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","best_parameters = grid_search.best_params_\n","print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","print(\"Best MAE: {:.2f}\".format(best_mae))\n","print(\"Best Parameters:\", best_parameters)\n","\n","# best rmse : 27,91\n","# best mae : 17.55\n","# Best Parameters: {'learning_rate': 0.075, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 64}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n","    }\n","\n","    model = LGBMRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n","\n","#Best RMSE: 29.84\n","#Best Parameters: {'learning_rate': 0.08593822799866623, 'n_estimators': 51, 'max_depth': 3, 'num_leaves': 37}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 27.83\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 28.83\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        'min_samples_split': [2, 5, 10],\n","    }\n","\n","    model = RandomForestRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 28.9\n","# Random Forest Regressor Best Parameters:  {'max_depth': 9, 'min_samples_split': 2, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":167,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       Train RMSE  Train MAE  Train MAPE  Test RMSE   \n","LinearRegression        21.703162  13.684898    7.741607  34.258355  \\\n","Lasso                   21.703164  13.684478    7.741256  34.257415   \n","LGBMRegressor           21.333447  13.672546    8.204027  34.433614   \n","RandomForestRegressor   18.387930  12.102468    6.926572  34.386210   \n","\n","                        Test MAE  Test MAPE   Test R2  \n","LinearRegression       21.730094  10.603651  0.953994  \n","Lasso                  21.729127  10.603570  0.953997  \n","LGBMRegressor          21.786026  10.816560  0.953522  \n","RandomForestRegressor  21.653319  10.567777  0.953650  \n"]}],"source":["train_set = data[data[\"datetime\"] <= '2023-04-30']\n","test_set = data[data[\"datetime\"] >= '2023-05-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        LinearRegression(),\n","        #Ridge(alpha=10.0),\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate= 0.08593822799866623, max_depth=3, n_estimators=51, num_leaves=37), #, subsample= 0.8, random_state=2345),\n","        RandomForestRegressor(random_state=0, max_depth=9, min_samples_split=2, n_estimators=200),\n","        #DecisionTreeRegressor(random_state=0, max_depth=7, min_samples_split=2)\n","    ]\n","\n","    # result_train = pd.DataFrame({'datetime': train_set[\"reg_date\"], 'day_of_reg': train_set[\"day_of_reg\"],\n","    #                              'pick_rgn2_nm': train_set[\"pick_rgn2_nm\"], 'hour_reg': train_set[\"hour_reg\"],\n","    #                              'is_rain': train_set[\"rain_group\"],  \"holiday_yn\" : train_set[\"holiday_yn\"],\n","    #                               'y_test': train_set[\"rider_cnt\"]})\n","\n","    # result_test = pd.DataFrame({'datetime': test_set[\"reg_date\"],\n","    #                             'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"],\n","    #                             'is_rain': test_set[\"rain_group\"], 'day_of_reg': test_set[\"day_of_reg\"], \n","    #                             'holiday_yn': test_set[\"holiday_yn\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","    result_train = pd.DataFrame({'reg_date': train_set[\"reg_date\"], 'datetime': train_set[\"datetime\"],'pick_rgn2_nn' : train_set[\"pick_rgn2_nm\"], 'y_test': train_set[\"rider_cnt\"]})\n","\n","    result_test = pd.DataFrame({'reg_date': test_set[\"reg_date\"], 'datetime' : test_set[\"datetime\"],'pick_rgn2_nn' : test_set[\"pick_rgn2_nm\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","\n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        cv_results = cross_validate(reg, X_train, y_train, cv = 5, scoring = scoring)\n","        \n","        reg.fit(X_train, y_train)\n","        y_pred_train = reg.predict(X_train)\n","        y_pred_test = reg.predict(X_test)\n","        \n","        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n","        mae_train = mean_absolute_error(y_train, y_pred_train)\n","        mape_train = MAPE(y_train, y_pred_train)\n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'Train RMSE': rmse_train,\n","            'Train MAE': mae_train,\n","            'Train MAPE': mape_train,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","         \n","        result_train[f'y_pred_train_{reg_name}'] = y_pred_train\n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","             \n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_pred1 = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    average_pred2 = (lgbm_pred+rf_pred) /2 \n","\n","    result_test['y_pred_test_avg1'] = average_pred1\n","    result_test['y_pred_test_avg2'] = average_pred2\n","\n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_train.to_csv('prediction_results_train_set.csv', index=False, encoding=\"cp949\")\n","    result_test.to_csv('prediction_results_test_set.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 세분화하여 MAE 값 확인"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['holiday_yn']).agg({\n","    'MAE_LinearRegression': np.mean,\n","  # 'MAE_Ridge': np.mean,\n","   'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","   'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['group_s']).agg({\n","    'MAE_LinearRegression': np.mean,\n"," # 'MAE_Ridge': np.mean,\n","    'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 세분화하여 MAPE 확인 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['is_rain', 'is_holiday']).agg({\n","    'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","    'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['hour_reg']).agg({\n","    'MAE_LinearRegression': np.mean,\n"," # 'MAE_Ridge': np.mean,\n","   # 'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    #'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['hour_reg']).agg({\n","  #  'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","  #  'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","   # 'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['group_s']).agg({\n","    'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","    'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 변수 중요도 파악 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### permutation importance -> RandomForest, LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    # train set에 대한 permutation importance 계산\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","\n","    # test set에 대한 permutation importance 계산\n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    # importance 값 저장 (numpy array를 list로 변환)\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    # importance 값에 따라 내림차순 정렬\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","\n","    # CSV 파일로 저장\n","    feature_importances.to_csv('feature_importances_lgbm.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","# LGBM 모델을 불러옴\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","\n","# permutation importance 계산\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","#print(scores_df)\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","    \n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","    \n","    feature_importances.to_csv('feature_importances_Rf.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","lgbm_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lasso_model = joblib.load('model_Lasso.joblib')\n","lasso_coef = pd.Series(lasso_model.coef_, index=X_train.columns)\n","selected_feats_lasso = lasso_coef[lasso_coef!=0].index\n","\n","print(\"Number of features selected by Lasso: \", len(selected_feats_lasso))\n","print(\"Features selected by Lasso: \", selected_feats_lasso)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_feature_importances(model, model_name):\n","    importances = model.feature_importances_\n","    feat_names = X_train.columns\n","    feature_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n","\n","    #print(\"Feature importances for \", model_name, \" : \")\n","    #print(feature_imp)\n","\n","    # Creating a bar plot\n","    plt.figure(figsize = (20,15))\n","    sns.barplot(x=feature_imp, y=feature_imp.index)\n","    # Add labels to your graph\n","    plt.xlabel('Feature Importance Score')\n","    plt.ylabel('Features')\n","    plt.title(\"Visualizing Important Features\")\n","    plt.legend()\n","    plt.show()\n","\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","plot_feature_importances(lgbm_model, 'LGBMRegressor')\n","\n","rf_model = joblib.load('model_RandomForestRegressor.joblib')\n","plot_feature_importances(rf_model, 'RandomForestRegressor')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
