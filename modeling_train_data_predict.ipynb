{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import joblib\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","import ast \n","import statsmodels.api as sm \n","from time import time\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[],"source":["data = pd.read_csv('combined_data.csv', encoding = \"cp949\")\n","data.head()\n","print(data.shape) #179,250"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","print(data.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n","data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","\n","data = data.sort_values(by=\"datetime\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = data.drop(columns = ['rider_cnt', 'order_cnt','temp_c','rain_c', \n","                            'snow_c', 'q1', 'q3', 'IQR1.5', 'outlier', 'day_of_reg2', 'is_holiday1'])\n","print(data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","print(data.shape) #179,250"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in ['pick_rgn2_nm', 'hour_reg', 'day_of_reg', 'is_rain', 'month', 'week', 'is_holiday2', 'specific_value'] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. numeric variable scale "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","#scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# df[num_vars] = scaler.fit_transform(df[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train/test set split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#np.random.seed(1234)\n","#df_train, df_test = train_test_split(dataset,train_size =0.75, test_size = 0.25, random_state = 100)\n","\n","df_train = df[df[\"datetime\"]<= '2022-12-31']\n","df_test = df[df[\"datetime\"] >= '2023-01-01']\n","\n","df_train = df_train.drop(columns = ['datetime', 'reg_date'])\n","df_test = df_test.drop(columns = ['datetime', 'reg_date'])\n","\n","print(df_train.shape, df_test.shape) #126000, 52,875, 77개"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt_2'])\n","y_train = df_train['rider_cnt_2']\n","\n","X_test = df_test.drop(columns=['rider_cnt_2'])\n","y_test = df_test['rider_cnt_2']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.Over Sampling "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["var = ['pick_rgn2_nm', 'hour_reg','day_of_reg', 'is_rain', 'month','week','is_holiday2','specific_value']\n","\n","encoder = OneHotEncoder()\n","onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","df = pd.concat([onehot, data.drop(columns=var)], axis=1)\n","#print(df.head(3))\n","print(df.columns)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = LGBMRegressor()\n","\n","parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","              {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","grid_search = GridSearchCV(estimator=classifier,\n","                           param_grid=parameters,\n","                           scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","                           cv=10,\n","                           n_jobs=-1,\n","                           refit='neg_mean_squared_error')                     \n","\n","grid_search.fit(X_train, y_train)\n","best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","best_parameters = grid_search.best_params_\n","print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","print(\"Best MAE: {:.2f}\".format(best_mae))\n","print(\"Best Parameters:\", best_parameters)\n","\n","# best rmse : 24.83\n","# best mae : 16.59\n","# Best Parameters: {'learning_rate': 0.125, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 64}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 26.09\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 26.03\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 25.89\n","# Random Forest Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 5, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# train_set = data[data[\"datetime\"] <= '2022-12-31']\n","# test_set = data[data[\"datetime\"] >= '2023-01-01']\n","\n","\n","# def execute_pipeline(X_train, y_train, X_test, y_test):\n","#     regressors = [\n","#         LinearRegression(),\n","#         Ridge(alpha=10.0),\n","#         Lasso(alpha=0.1, max_iter=5000),\n","#         LGBMRegressor(learning_rate=0.125, max_depth=7, n_estimators=200, num_leaves=64),\n","#         RandomForestRegressor(random_state=0, max_depth=7, min_samples_split=5, n_estimators=200),\n","#         DecisionTreeRegressor(random_state=0, max_depth=7, min_samples_split=2)\n","#      ]\n","\n","#     result_train = pd.DataFrame({'datetime': train_set[\"datetime\"], 'day_of_reg' : train_set[\"day_of_reg\"],\n","#                                  'pick_rgn2_nm': train_set[\"pick_rgn2_nm\"], 'hour_reg': train_set[\"hour_reg\"],\n","#                                   'is_rain': train_set[\"is_rain\"] ,\n","#                                  'is_holiday': train_set[\"is_holiday2\"], 'y_test': y_train})\n","\n","#     result_test = pd.DataFrame({'datetime': test_set[\"datetime\"], \n","#                                 'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"],\n","#                                 'is_rain': test_set[\"is_rain\"],'day_of_reg' : test_set[\"day_of_reg\"],\n","#                                 'is_holiday': test_set[\"is_holiday2\"], 'y_test': y_test})\n","\n","#     scores = {}\n","#     predictions = {}\n","    \n","#     for reg in regressors:\n","#         reg_name = reg.__class__.__name__\n","#         scoring = {\n","#             'rmse': 'neg_root_mean_squared_error',\n","#             'mae': 'neg_mean_absolute_error',\n","#             'r2': 'r2'\n","#                     }\n","        \n","#         # 학습할 때 사용한 피처의 순서를 저장\n","#         # cv_results = cross_validate(reg, X_train, y_train, cv=10, scoring=scoring)\n","\n","#         # mean_rmse = -1.0 * np.mean(cv_results['test_rmse'])\n","#         # std_rmse = np.std(cv_results['test_rmse'])\n","#         # mean_mae = -1.0 * np.mean(cv_results['test_mae'])\n","#         # std_mae = np.std(cv_results['test_mae'])\n","#         # mean_r2 = np.mean(cv_results['test_r2'])\n","#         # std_r2 = np.std(cv_results['test_r2'])\n","\n","#         reg.fit(X_train, y_train)\n","#         y_pred_train = reg.predict(X_train)\n","#         y_pred_test = reg.predict(X_test)\n","\n","#         rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n","#         mae_train = mean_absolute_error(y_train, y_pred_train)\n","#         mape_train = MAPE(y_train, y_pred_train)\n","#         rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","#         mae_test = mean_absolute_error(y_test, y_pred_test)\n","#         mape_test = MAPE(y_test, y_pred_test)\n","#         r2_test = r2_score(y_test, y_pred_test)\n","\n","#         # 모델 저장\n","#         model_file = f'model_{reg_name}.joblib'\n","#         joblib.dump(reg, model_file)\n","\n","#         scores[reg_name] = {\n","#             # 'CV RMSE Mean': mean_rmse,\n","#             # 'CV RMSE Std': std_rmse,\n","#             # 'CV MAE Mean': mean_mae,\n","#             # 'CV MAE Std': std_mae,\n","#             # 'CV R2 Mean': mean_r2,\n","#             # 'CV R2 Std': std_r2,\n","#             'Train RMSE': rmse_train,\n","#             'Train MAE': mae_train,\n","#             'Train MAPE' : mape_train ,\n","#             'Test RMSE': rmse_test,\n","#             'Test MAE' : mae_test,\n","#             'Test MAPE' : mape_test,\n","#             'Test R2' : r2_test \n","#         }\n","        \n","#         result_train[f'y_pred_train_{reg_name}'] = y_pred_train\n","#         result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","#         predictions[reg_name] = y_pred_test\n","    \n","#     lasso_pred = predictions['Lasso']\n","#     lgbm_pred = predictions['LGBMRegressor']\n","#     rf_pred = predictions['RandomForestRegressor']\n","#     average_pred = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    \n","#     result_test['Average Prediction'] = average_pred\n","    \n","#     scores_df = pd.DataFrame(scores).transpose()\n","\n","#     # train, test 예측치 저장\n","#     result_train.to_csv('prediction_results_train_set.csv', index=False, encoding=\"cp949\")\n","#     result_test.to_csv('prediction_results_test_set.csv', index=False, encoding=\"cp949\")\n","\n","#     return scores_df\n","\n","# # usage \n","# scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","# print(scores_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_set = data[data[\"datetime\"] <= '2022-12-31']\n","test_set = data[data[\"datetime\"] >= '2023-01-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        LinearRegression(),\n","        Ridge(alpha=10.0),\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate=0.125, max_depth=7, n_estimators=200, num_leaves=64),\n","        RandomForestRegressor(random_state=0, max_depth=7, min_samples_split=5, n_estimators=200),\n","        DecisionTreeRegressor(random_state=0, max_depth=7, min_samples_split=2)\n","    ]\n","\n","    result_train = pd.DataFrame({'datetime': train_set[\"datetime\"], 'day_of_reg': train_set[\"day_of_reg\"],\n","                                 'pick_rgn2_nm': train_set[\"pick_rgn2_nm\"], 'hour_reg': train_set[\"hour_reg\"],\n","                                 'is_rain': train_set[\"is_rain\"],\n","                                 'is_holiday': train_set[\"is_holiday2\"], 'y_test': y_train})\n","\n","    result_test = pd.DataFrame({'datetime': test_set[\"datetime\"],\n","                                'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"],\n","                                'is_rain': test_set[\"is_rain\"], 'day_of_reg': test_set[\"day_of_reg\"],\n","                                'is_holiday': test_set[\"is_holiday2\"], 'y_test': y_test})\n","\n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        #cv_results = cross_validate(reg, X_train, y_train, cv = 5, scoring = scoring)\n","        \n","        reg.fit(X_train, y_train)\n","        y_pred_train = reg.predict(X_train)\n","        y_pred_test = reg.predict(X_test)\n","\n","        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n","        mae_train = mean_absolute_error(y_train, y_pred_train)\n","        mape_train = MAPE(y_train, y_pred_train)\n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'Train RMSE': rmse_train,\n","            'Train MAE': mae_train,\n","            'Train MAPE': mape_train,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","\n","        result_train[f'y_pred_train_{reg_name}'] = y_pred_train\n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_pred = (lasso_pred + lgbm_pred + rf_pred) / 3\n","\n","    result_test['y_pred_test_avg'] = average_pred\n","\n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_train.to_csv('prediction_results_train_set.csv', index=False, encoding=\"cp949\")\n","    result_test.to_csv('prediction_results_test_set.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 다음주 6일 예측하기"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_data = pd.read_csv('predict_data.csv', encoding = \"cp949\")\n","new_data.head()\n","print(new_data.shape) #2250,20"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(new_data.info())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","new_data = new_data.sort_values(by=\"reg_date\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_data = new_data.drop(columns = ['day_of_reg2', 'is_holiday'])\n","print(new_data.head())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in ['pick_rgn2_nm', 'hour_reg', 'day_of_reg', 'is_rain', 'month', 'week', 'is_holiday2'] : \n","   new_data[col] = new_data[col].astype('category')\n","\n","print(new_data.dtypes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# one-hot-encoding\n","\n","var = ['pick_rgn2_nm', 'hour_reg','day_of_reg', 'is_rain', 'month','week','is_holiday2']\n","\n","encode_data = new_data.sort_values(by=\"reg_date\")\n","X_test = encode_data.drop(columns = ['reg_date'])\n","\n","encoder = OneHotEncoder()\n","onehot = pd.DataFrame(encoder.fit_transform(encode_data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = encode_data.index)\n","X_test = pd.concat([onehot, X_test.drop(columns=var)], axis=1)\n","#print(X_test.head(3))\n","print(X_test.columns)\n","\n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 존재하지 않는 변수 추가하기 (month,week)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 새로운 변수 생성\n","new_variables = ['month_1', 'month_2', 'month_3', 'month_4', 'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11', 'month_12', 'week_1', 'week_3', 'week_4', 'week_5', 'is_holiday2_1']\n","\n","# 새로운 변수를 포함한 빈 DataFrame 생성\n","encode_data = pd.DataFrame(0, columns=new_variables, index= X_test.index)\n","\n","# 기존 x_test DataFrame과 새로운 변수를 포함한 DataFrame을 병합\n","X_test = pd.concat([X_test, encode_data], axis=1)\n","\n","# 결과 확인\n","#print(X_test.head())\n","print(X_test.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### train/test set split "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(X_test.shape) # 2250,72"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.isna().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["desired_order = ['pick_rgn2_nm_강남구', 'pick_rgn2_nm_강동구', 'pick_rgn2_nm_강북구',\n","       'pick_rgn2_nm_강서구', 'pick_rgn2_nm_관악구', 'pick_rgn2_nm_광진구',\n","       'pick_rgn2_nm_구로구', 'pick_rgn2_nm_금천구', 'pick_rgn2_nm_노원구',\n","       'pick_rgn2_nm_도봉구', 'pick_rgn2_nm_동대문구', 'pick_rgn2_nm_동작구',\n","       'pick_rgn2_nm_마포구', 'pick_rgn2_nm_서대문구', 'pick_rgn2_nm_서초구',\n","       'pick_rgn2_nm_성동구', 'pick_rgn2_nm_성북구', 'pick_rgn2_nm_송파구',\n","       'pick_rgn2_nm_양천구', 'pick_rgn2_nm_영등포구', 'pick_rgn2_nm_용산구',\n","       'pick_rgn2_nm_은평구', 'pick_rgn2_nm_종로구', 'pick_rgn2_nm_중구',\n","       'pick_rgn2_nm_중랑구', 'hour_reg_9', 'hour_reg_10', 'hour_reg_11',\n","       'hour_reg_12', 'hour_reg_13', 'hour_reg_14', 'hour_reg_15',\n","       'hour_reg_16', 'hour_reg_17', 'hour_reg_18', 'hour_reg_19',\n","       'hour_reg_20', 'hour_reg_21', 'hour_reg_22', 'hour_reg_23',\n","       'day_of_reg_금', 'day_of_reg_월목', 'day_of_reg_주말', 'is_rain_0',\n","       'is_rain_1', 'month_1', 'month_2', 'month_3', 'month_4', 'month_5',\n","       'month_6', 'month_7', 'month_8', 'month_9', 'month_10', 'month_11',\n","       'month_12', 'week_1', 'week_2', 'week_3', 'week_4', 'week_5',\n","       'is_holiday2_0', 'is_holiday2_1', 'rider_cnt_w_1', 'rider_cnt_w_2',\n","       'rider_cnt_w_3', 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2',\n","       'order_cnt_w_3', 'order_cnt_w_4']\n","\n","X_test = X_test[desired_order]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def get_predict(X_test):\n","\n","    linear_model = joblib.load('model_LinearRegression.joblib')\n","    LGBM_model = joblib.load('model_LGBMRegressor.joblib')\n","    RF_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","    result_df = pd.DataFrame({'reg_date': new_data[\"reg_date\"],\n","                              'pick_rgn2_nm': new_data[\"pick_rgn2_nm\"], 'hour_reg': new_data[\"hour_reg\"],\n","                              'day_of_reg': new_data[\"day_of_reg\"], 'is_rain': new_data[\"is_rain\"],\n","                              'is_holiday': new_data[\"is_holiday2\"]})\n","\n","    y_pred_linear = linear_model.predict(X_test)\n","    y_pred_LGBM = LGBM_model.predict(X_test)\n","    y_pred_RF = RF_model.predict(X_test)\n","    \n","    result_df['y_pred_linear'] = y_pred_linear\n","    result_df['y_pred_LGBM'] = y_pred_LGBM\n","    result_df['y_pred_RF'] = y_pred_RF\n","\n","    result_df.to_csv('prediction_results_latest6days.csv', index=False, encoding=\"cp949\")\n","\n","\n","get_predict(X_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
