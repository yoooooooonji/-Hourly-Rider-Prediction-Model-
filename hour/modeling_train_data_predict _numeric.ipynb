{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/yj.noh/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import optuna\n","import joblib\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import font_manager\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.inspection import permutation_importance\n","import statsmodels.api as sm \n","from time import time\n","\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 한글 폰트 경로 설정\n","font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'\n","font_name = font_manager.FontProperties(fname=font_path).get_name()\n","plt.rc('font', family=font_name)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(44625, 14)\n"]}],"source":["data = pd.read_csv('combined_data.csv', encoding = \"cp949\")\n","data.head()\n","print(data.shape) "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 44625 entries, 0 to 44624\n","Data columns (total 14 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   day_of_reg         44625 non-null  object \n"," 1   pick_rgn2_nm       44625 non-null  object \n"," 2   rider_cnt          44625 non-null  float64\n"," 3   datetime           44625 non-null  object \n"," 4   hour_reg           44625 non-null  int64  \n"," 5   reg_date           44625 non-null  object \n"," 6   rain_group         44625 non-null  object \n"," 7   holiday_yn         44625 non-null  object \n"," 8   rider_cnt_w_1_new  44625 non-null  float64\n"," 9   rider_cnt_w_2_new  44625 non-null  float64\n"," 10  rider_cnt_w_3_new  44625 non-null  float64\n"," 11  rider_cnt_w_4_new  44625 non-null  float64\n"," 12  order_cnt_w_1_new  44625 non-null  int64  \n"," 13  group_s            44625 non-null  object \n","dtypes: float64(5), int64(2), object(7)\n","memory usage: 4.8+ MB\n","None\n","          rider_cnt      hour_reg  rider_cnt_w_1_new  rider_cnt_w_2_new   \n","count  44625.000000  44625.000000       44625.000000       44625.000000  \\\n","mean     216.220017     16.000000         214.209003         213.491686   \n","std      157.533733      4.320542         156.491066         155.875738   \n","min        7.000000      9.000000           7.000000           9.000000   \n","25%      105.000000     12.000000         104.000000         104.000000   \n","50%      175.000000     16.000000         174.000000         173.000000   \n","75%      282.000000     20.000000         279.000000         278.000000   \n","max     1063.000000     23.000000        1063.000000        1063.000000   \n","\n","       rider_cnt_w_3_new  rider_cnt_w_4_new  order_cnt_w_1_new  \n","count       44625.000000       44625.000000       44625.000000  \n","mean          213.066151         213.560168         436.168246  \n","std           155.826425         156.257629         390.788600  \n","min             9.000000          10.000000           8.000000  \n","25%           103.000000         104.000000         175.000000  \n","50%           173.000000         173.000000         320.000000  \n","75%           277.000000         277.000000         561.000000  \n","max          1063.000000        1063.000000        3506.000000  \n"]}],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","print(data.describe())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n","data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","\n","data = data.sort_values(by=\"datetime\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data = data.drop(columns = [''holiday_yn','hour_reg','day_of_reg','rain_group''])\n","# print(data.head())"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["day_of_reg           0\n","pick_rgn2_nm         0\n","rider_cnt            0\n","datetime             0\n","hour_reg             0\n","reg_date             0\n","rain_group           0\n","holiday_yn           0\n","rider_cnt_w_1_new    0\n","rider_cnt_w_2_new    0\n","rider_cnt_w_3_new    0\n","rider_cnt_w_4_new    0\n","order_cnt_w_1_new    0\n","group_s              0\n","dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","#print(data.shape) "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[{"name":"stdout","output_type":"stream","text":["day_of_reg                 category\n","pick_rgn2_nm               category\n","rider_cnt                   float64\n","datetime             datetime64[ns]\n","hour_reg                   category\n","reg_date             datetime64[ns]\n","rain_group                 category\n","holiday_yn                 category\n","rider_cnt_w_1_new           float64\n","rider_cnt_w_2_new           float64\n","rider_cnt_w_3_new           float64\n","rider_cnt_w_4_new           float64\n","order_cnt_w_1_new             int64\n","group_s                    category\n","dtype: object\n"]}],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in ['pick_rgn2_nm', 'hour_reg', 'day_of_reg',  'holiday_yn' ,'rain_group', 'group_s'] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","# #scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# data[num_vars] = scaler.fit_transform(data[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg', 'pick_rgn2_nm', 'rider_cnt', 'datetime', 'hour_reg',\n","       'reg_date', 'rain_group', 'holiday_yn', 'rider_cnt_w_1_new',\n","       'rider_cnt_w_2_new', 'rider_cnt_w_3_new', 'rider_cnt_w_4_new',\n","       'order_cnt_w_1_new', 'group_s'],\n","      dtype='object')\n"]}],"source":["#df = data.drop(columns = ['is_rain','is_holiday','day_of_reg'])\n","df = data\n","# var = ['pick_rgn2_nm', 'hour_reg', 'day_of_reg', 'rain_group', 'holiday_yn']\n","# encoder = OneHotEncoder()\n","# onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","# df = pd.concat([onehot, df.drop(columns=var)], axis=1)\n","#print(df.head(3))\n","print(df.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train, test set split"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(33000, 6) (11250, 6)\n"]}],"source":["# train_ratio = 0.8\n","# total_samples = df.shape[0]\n","# train_samples = int(train_ratio * total_samples)\n","# df_train = df[:train_samples]\n","# df_test = df[train_samples:]\n","\n","df_train = df[df[\"datetime\"]<= '2023-04-30']\n","df_test = df[df[\"datetime\"] >= '2023-05-01']\n","\n","# print(df_train['reg_date'].min()) #2022-01-29\n","# print(df_test['reg_date'].min()) #2023-02-15\n","\n","# print(df_train['reg_date'].max()) #2023-02-15\n","# print(df_test['reg_date'].max()) #2023-05-21\n","\n","df_train = df_train.drop(columns = ['datetime', 'reg_date', 'pick_rgn2_nm', 'day_of_reg','hour_reg','rain_group','holiday_yn','group_s'])\n","df_test = df_test.drop(columns = ['datetime', 'reg_date', 'pick_rgn2_nm', 'day_of_reg','hour_reg','rain_group','holiday_yn','group_s'])\n","print(df_train.shape, df_test.shape) # 126,000, 54375 / 33000 11250 "]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(33000, 5) (33000,) (11250, 5) (11250,)\n"]}],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt'])\n","y_train = df_train['rider_cnt']\n","\n","X_test = df_test.drop(columns=['rider_cnt'])\n","y_test = df_test['rider_cnt']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['rider_cnt_w_1_new', 'rider_cnt_w_2_new', 'rider_cnt_w_3_new',\n","       'rider_cnt_w_4_new', 'order_cnt_w_1_new'],\n","      dtype='object')\n"]}],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### numeric_scale "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 입력 변수 \n","# numeric_cols = ['rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#                 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#                 'order_cnt_w_4']\n","\n","# # scaler \n","# scaler_X = StandardScaler()\n","\n","# # X_train, X_test\n","# X_train_scaled = scaler_X.fit_transform(X_train[numeric_cols])\n","# X_test_scaled = scaler_X.transform(X_test[numeric_cols])\n","\n","# # 스케일링된 결과를 DataFrame으로 변환\n","# X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_cols, index = X_train.index)\n","# X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_cols, index = X_test.index)\n","\n","# # 원래의 범주형 변수들을 선택\n","# categorical_cols = [col for col in X_train.columns if col not in numeric_cols]\n","# X_train_cat = X_train[categorical_cols]\n","# X_test_cat = X_test[categorical_cols]\n","\n","# # 스케일링된 DataFrame과 범주형 변수들을 병합\n","# X_train_final = pd.concat([X_train_scaled, X_train_cat], axis=1)\n","# X_test_final = pd.concat([X_test_scaled, X_test_cat], axis=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측값\n","# y_train, y_test\n","# scaler_y = StandardScaler()\n","# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n","# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n","# y_train_scaled = y_train_scaled.ravel()\n","# y_test_scaled=  y_test_scaled.ravel()\n","\n","# print(y_train_scaled.shape)\n","# print(y_test_scaled.shape)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:              rider_cnt   R-squared:                       0.985\n","Model:                            OLS   Adj. R-squared:                  0.985\n","Method:                 Least Squares   F-statistic:                 4.313e+05\n","Date:                Wed, 31 May 2023   Prob (F-statistic):               0.00\n","Time:                        19:17:06   Log-Likelihood:            -1.4438e+05\n","No. Observations:               33000   AIC:                         2.888e+05\n","Df Residuals:                   32994   BIC:                         2.888e+05\n","Df Model:                           5                                         \n","Covariance Type:            nonrobust                                         \n","=====================================================================================\n","                        coef    std err          t      P>|t|      [0.025      0.975]\n","-------------------------------------------------------------------------------------\n","const                 0.7206      0.217      3.316      0.001       0.295       1.147\n","rider_cnt_w_1_new     0.3618      0.006     62.888      0.000       0.351       0.373\n","rider_cnt_w_2_new     0.2648      0.005     51.684      0.000       0.255       0.275\n","rider_cnt_w_3_new     0.1738      0.005     31.820      0.000       0.163       0.185\n","rider_cnt_w_4_new     0.1661      0.005     31.803      0.000       0.156       0.176\n","order_cnt_w_1_new     0.0137      0.001      9.818      0.000       0.011       0.016\n","==============================================================================\n","Omnibus:                     5985.372   Durbin-Watson:                   1.258\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):            98966.909\n","Skew:                           0.393   Prob(JB):                         0.00\n","Kurtosis:                      11.447   Cond. No.                     1.61e+03\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The condition number is large, 1.61e+03. This might indicate that there are\n","strong multicollinearity or other numerical problems.\n"]}],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 선형 회귀 모델 학습\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 잔차 계산\n","y_pred = model.predict(X_test)\n","residuals = y_test - y_pred\n","\n","# 변수별 잔차 그래프 그리기\n","for column in X_test.columns:\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x=X_test[column], y=residuals)\n","    plt.title(f'Residuals vs. {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Residuals')\n","    plt.show()\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = LGBMRegressor()\n","\n","parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","              {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","grid_search = GridSearchCV(estimator=classifier,\n","                           param_grid=parameters,\n","                           scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","                           cv=10,\n","                           n_jobs=-1,\n","                           refit='neg_mean_squared_error')                     \n","\n","grid_search.fit(X_train, y_train)\n","best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","best_parameters = grid_search.best_params_\n","print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","print(\"Best MAE: {:.2f}\".format(best_mae))\n","print(\"Best Parameters:\", best_parameters)\n","\n","# best rmse : 27,91\n","# best mae : 17.55\n","# Best Parameters: {'learning_rate': 0.075, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 64}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n","    }\n","\n","    model = LGBMRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n","\n","#Best RMSE: 29.84\n","#Best Parameters: {'learning_rate': 0.08593822799866623, 'n_estimators': 51, 'max_depth': 3, 'num_leaves': 37}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 27.83\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 28.83\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        'min_samples_split': [2, 5, 10],\n","    }\n","\n","    model = RandomForestRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 28.9\n","# Random Forest Regressor Best Parameters:  {'max_depth': 9, 'min_samples_split': 2, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       Train RMSE  Train MAE  Train MAPE  Test RMSE   \n","LinearRegression        19.226402  12.734823    7.276264  31.635375  \\\n","Lasso                   19.226405  12.734365    7.275994  31.634513   \n","LGBMRegressor           18.894190  12.732869    7.746841  31.870802   \n","RandomForestRegressor   15.954123  11.119732    6.454530  31.803560   \n","\n","                        Test MAE  Test MAPE   Test R2  \n","LinearRegression       20.823388  10.270980  0.960769  \n","Lasso                  20.822484  10.270934  0.960772  \n","LGBMRegressor          20.827192  10.407691  0.960183  \n","RandomForestRegressor  20.684278  10.188820  0.960351  \n"]}],"source":["train_set = data[data[\"datetime\"] <= '2023-04-30']\n","test_set = data[data[\"datetime\"] >= '2023-05-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        LinearRegression(),\n","        #Ridge(alpha=10.0),\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate= 0.08593822799866623, max_depth=3, n_estimators=51, num_leaves=37), #, subsample= 0.8, random_state=2345),\n","        RandomForestRegressor(random_state=0, max_depth=9, min_samples_split=2, n_estimators=200),\n","        #DecisionTreeRegressor(random_state=0, max_depth=7, min_samples_split=2)\n","    ]\n","\n","    # result_train = pd.DataFrame({'datetime': train_set[\"reg_date\"], 'day_of_reg': train_set[\"day_of_reg\"],\n","    #                              'pick_rgn2_nm': train_set[\"pick_rgn2_nm\"], 'hour_reg': train_set[\"hour_reg\"],\n","    #                              'is_rain': train_set[\"rain_group\"],  \"holiday_yn\" : train_set[\"holiday_yn\"],\n","    #                               'y_test': train_set[\"rider_cnt\"]})\n","\n","    # result_test = pd.DataFrame({'datetime': test_set[\"reg_date\"],\n","    #                             'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"],\n","    #                             'is_rain': test_set[\"rain_group\"], 'day_of_reg': test_set[\"day_of_reg\"], \n","    #                             'holiday_yn': test_set[\"holiday_yn\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","    result_train = pd.DataFrame({'reg_date': train_set[\"reg_date\"], 'day_of_reg': train_set[\"day_of_reg\"],\n","                                 'pick_rgn2_nm': train_set[\"pick_rgn2_nm\"], 'hour_reg': train_set[\"hour_reg\"],\n","                                 'is_rain': train_set[\"rain_group\"],  \"holiday_yn\" : train_set[\"holiday_yn\"], \"group_s\" : train_set[\"group_s\"],\n","                                  'y_test': train_set[\"rider_cnt\"]})\n","\n","    result_test = pd.DataFrame({'reg_date': test_set[\"reg_date\"],\n","                                'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"],\n","                                'is_rain': test_set[\"rain_group\"], 'day_of_reg': test_set[\"day_of_reg\"], \"group_s\" : test_set[\"group_s\"],\n","                                'holiday_yn': test_set[\"holiday_yn\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","    \n","\n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        cv_results = cross_validate(reg, X_train, y_train, cv = 5, scoring = scoring)\n","        \n","        reg.fit(X_train, y_train)\n","        y_pred_train = reg.predict(X_train)\n","        y_pred_test = reg.predict(X_test)\n","        \n","        rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n","        mae_train = mean_absolute_error(y_train, y_pred_train)\n","        mape_train = MAPE(y_train, y_pred_train)\n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'Train RMSE': rmse_train,\n","            'Train MAE': mae_train,\n","            'Train MAPE': mape_train,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","         \n","        result_train[f'y_pred_train_{reg_name}'] = y_pred_train\n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","             \n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_pred1 = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    average_pred2 = (lgbm_pred+rf_pred) /2 \n","\n","    result_test['y_pred_test_avg1'] = average_pred1\n","    result_test['y_pred_test_avg2'] = average_pred2\n","\n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_train.to_csv('prediction_results_train_set.csv', index=False, encoding=\"cp949\")\n","    result_test.to_csv('prediction_results_test_set.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 세분화하여 MAE 값 확인"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  holiday_yn  MAE_LinearRegression  MAE_Lasso  MAE_LGBMRegressor   \n","0          N             19.892954  19.891887          19.826622  \\\n","1          Y             22.994399  22.993878          23.161853   \n","\n","   MAE_RandomForestRegressor   MAE_avg1   MAE_avg2  \n","0                  19.667679  19.501239  19.463883  \n","1                  23.056341  22.968814  23.018640  \n"]}],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['holiday_yn']).agg({\n","    'MAE_LinearRegression': np.mean,\n","  # 'MAE_Ridge': np.mean,\n","   'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","   'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  group_s  MAE_LinearRegression  MAE_Lasso  MAE_LGBMRegressor   \n","0       A             19.695271  19.694492          19.581014  \\\n","1       B             23.846623  23.839780          24.738797   \n","2       D             25.953448  25.952061          26.136753   \n","3       E             22.431017  22.429824          22.609394   \n","4       F             22.947020  22.947906          23.090985   \n","\n","   MAE_RandomForestRegressor   MAE_avg1   MAE_avg2  \n","0                  19.433423  19.266407  19.214868  \n","1                  24.352806  24.197884  24.444185  \n","2                  25.446537  25.745324  25.725719  \n","3                  22.096825  22.288626  22.266485  \n","4                  23.858802  23.176957  23.369873  \n"]}],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['group_s']).agg({\n","    'MAE_LinearRegression': np.mean,\n"," # 'MAE_Ridge': np.mean,\n","    'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 세분화하여 MAPE 확인 "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  is_rain holiday_yn  MAPE_LinearRegression  MAPE_Lasso  MAPE_LGBMRegressor   \n","0      no          N              10.525525   10.525494           10.676970  \\\n","1      no          Y               9.188866    9.188555            9.183857   \n","2  normal          Y              11.769056   11.770800           12.451111   \n","3    weak          N              14.076375   14.079295           14.601694   \n","4    weak          Y               9.960339    9.960009           10.087638   \n","\n","   MAPE_RandomForestRegressor  MAPE_avg1  MAPE_avg2  \n","0                   10.373349  10.275223  10.278640  \n","1                    9.129719   9.114364   9.109426  \n","2                   12.409498  12.186508  12.407299  \n","3                   14.494997  14.391995  14.548345  \n","4                   10.153642   9.968042  10.046717  \n"]}],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['is_rain', 'holiday_yn']).agg({\n","    'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","    'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    hour_reg  MAE_LinearRegression  MAE_LGBMRegressor   \n","0          9              7.981128           8.377598  \\\n","1         10             14.362534          14.174430   \n","2         11             22.438103          22.519827   \n","3         12             26.070571          26.058307   \n","4         13             23.276154          23.024150   \n","5         14             18.109090          17.831404   \n","6         15             25.182044          24.732254   \n","7         16             29.922451          29.740573   \n","8         17             25.413069          25.548596   \n","9         18             24.528547          25.241206   \n","10        19             25.539450          26.092858   \n","11        20             24.391195          24.474336   \n","12        21             18.657794          18.577984   \n","13        22             14.914803          14.739810   \n","14        23             11.563883          11.274541   \n","\n","    MAE_RandomForestRegressor   MAE_avg1  \n","0                    8.099452   7.875542  \n","1                   14.375611  14.173200  \n","2                   21.970744  22.118002  \n","3                   25.252200  25.398117  \n","4                   22.732331  22.543626  \n","5                   17.646706  17.520336  \n","6                   24.963325  24.697155  \n","7                   29.723144  29.537163  \n","8                   25.346698  25.246685  \n","9                   24.676707  24.625498  \n","10                  26.026910  25.658537  \n","11                  24.404578  24.194457  \n","12                  18.400773  18.423383  \n","13                  14.956479  14.752920  \n","14                  11.688506  11.358050  \n"]}],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","#predict['MAE_Ridge'] = abs(predict['y_pred_test_Ridge'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","#predict['MAE_DecisionTreeRegressor'] = abs(predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg1'] = abs(predict['y_pred_test_avg1'] - predict['y_test'])\n","predict['MAE_avg2'] = abs(predict['y_pred_test_avg2'] - predict['y_test'])\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['hour_reg']).agg({\n","    'MAE_LinearRegression': np.mean,\n"," # 'MAE_Ridge': np.mean,\n","   # 'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","  # 'MAE_DecisionTreeRegressor': np.mean,\n","    'MAE_avg1' : np.mean,\n","    #'MAE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["    hour_reg  MAPE_LGBMRegressor  MAPE_RandomForestRegressor  MAPE_avg1\n","0          9           18.533187                   15.315426  15.406791\n","1         10           11.723156                   11.795857  11.678733\n","2         11            8.668042                    8.487917   8.527072\n","3         12            9.327791                    9.183245   9.118059\n","4         13           10.330048                   10.214789  10.061526\n","5         14           10.841223                   10.562843  10.551633\n","6         15           14.030200                   14.133227  13.945063\n","7         16           13.780959                   13.776001  13.631230\n","8         17            8.702517                    8.721177   8.646823\n","9         18            6.664656                    6.583648   6.559165\n","10        19            6.783724                    6.801368   6.703643\n","11        20            7.913888                    7.948906   7.861540\n","12        21            8.845167                    8.832365   8.782887\n","13        22            9.383793                    9.513820   9.374062\n","14        23           10.587018                   10.961709  10.594648\n"]}],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['hour_reg']).agg({\n","  #  'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","  #  'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","   # 'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_Ridge'] = abs((predict['y_pred_test_Ridge'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","#predict['MAPE_DecisionTreeRegressor'] = abs((predict['y_pred_test_DecisionTreeRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg1'] = abs((predict['y_pred_test_avg1'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg2'] = abs((predict['y_pred_test_avg2'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['group_s']).agg({\n","    'MAPE_LinearRegression': np.mean,\n"," #   'MAPE_Ridge': np.mean,\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","  #  'MAPE_DecisionTreeRegressor': np.mean,\n","    'MAPE_avg1' : np.mean,\n","    'MAPE_avg2' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 변수 중요도 파악 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### permutation importance -> RandomForest, LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    # train set에 대한 permutation importance 계산\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","\n","    # test set에 대한 permutation importance 계산\n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    # importance 값 저장 (numpy array를 list로 변환)\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    # importance 값에 따라 내림차순 정렬\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","\n","    # CSV 파일로 저장\n","    feature_importances.to_csv('feature_importances_lgbm.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","# LGBM 모델을 불러옴\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","\n","# permutation importance 계산\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","#print(scores_df)\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","    \n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","    \n","    feature_importances.to_csv('feature_importances_Rf.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","lgbm_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lasso_model = joblib.load('model_Lasso.joblib')\n","lasso_coef = pd.Series(lasso_model.coef_, index=X_train.columns)\n","selected_feats_lasso = lasso_coef[lasso_coef!=0].index\n","\n","print(\"Number of features selected by Lasso: \", len(selected_feats_lasso))\n","print(\"Features selected by Lasso: \", selected_feats_lasso)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_feature_importances(model, model_name):\n","    importances = model.feature_importances_\n","    feat_names = X_train.columns\n","    feature_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n","\n","    #print(\"Feature importances for \", model_name, \" : \")\n","    #print(feature_imp)\n","\n","    # Creating a bar plot\n","    plt.figure(figsize = (20,15))\n","    sns.barplot(x=feature_imp, y=feature_imp.index)\n","    # Add labels to your graph\n","    plt.xlabel('Feature Importance Score')\n","    plt.ylabel('Features')\n","    plt.title(\"Visualizing Important Features\")\n","    plt.legend()\n","    plt.show()\n","\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","plot_feature_importances(lgbm_model, 'LGBMRegressor')\n","\n","rf_model = joblib.load('model_RandomForestRegressor.joblib')\n","plot_feature_importances(rf_model, 'RandomForestRegressor')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
