{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":40,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import optuna\n","import joblib\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import font_manager\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.inspection import permutation_importance\n","import statsmodels.api as sm \n","from time import time\n","\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 한글 폰트 경로 설정\n","font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'\n","font_name = font_manager.FontProperties(fname=font_path).get_name()\n","plt.rc('font', family=font_name)"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2385, 15)\n"]}],"source":["data = pd.read_csv('combined_data.csv', encoding = \"cp949\")\n","data.head()\n","\n","#data = data[data['pick_rgn2_nm']=='강남구']\n","print(data.shape) "]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Index: 2385 entries, 0 to 59600\n","Data columns (total 15 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   holiday_yn     2385 non-null   object \n"," 1   pick_rgn2_nm   2385 non-null   object \n"," 2   rider_cnt      2385 non-null   float64\n"," 3   datetime       2385 non-null   object \n"," 4   hour_reg       2385 non-null   int64  \n"," 5   reg_date       2385 non-null   object \n"," 6   day_of_reg     2385 non-null   object \n"," 7   is_rain        2385 non-null   int64  \n"," 8   rain_group     2385 non-null   object \n"," 9   rider_cnt_w_1  2385 non-null   float64\n"," 10  rider_cnt_w_2  2385 non-null   float64\n"," 11  rider_cnt_w_3  2385 non-null   float64\n"," 12  rider_cnt_w_4  2385 non-null   float64\n"," 13  order_cnt_w_1  2385 non-null   int64  \n"," 14  group_s        2385 non-null   object \n","dtypes: float64(5), int64(3), object(7)\n","memory usage: 298.1+ KB\n","None\n","         rider_cnt   hour_reg      is_rain  rider_cnt_w_1  rider_cnt_w_2   \n","count  2385.000000  2385.0000  2385.000000     2385.00000    2385.000000  \\\n","mean    571.349686    16.0000     0.061635      570.07065     568.717191   \n","std     223.750376     4.3214     0.240542      224.38830     225.091189   \n","min     127.000000     9.0000     0.000000      127.00000     127.000000   \n","25%     401.000000    12.0000     0.000000      400.00000     399.000000   \n","50%     520.000000    16.0000     0.000000      519.00000     515.000000   \n","75%     746.000000    20.0000     0.000000      743.00000     740.000000   \n","max    1063.000000    23.0000     1.000000     1064.00000    1064.000000   \n","\n","       rider_cnt_w_3  rider_cnt_w_4  order_cnt_w_1  \n","count    2385.000000    2385.000000    2385.000000  \n","mean      568.143396     567.200000    1348.485954  \n","std       225.598453     225.686296     612.254599  \n","min       127.000000     127.000000     199.000000  \n","25%       399.000000     399.000000     885.000000  \n","50%       514.000000     511.000000    1196.000000  \n","75%       737.000000     731.000000    1778.000000  \n","max      1064.000000    1064.000000    3506.000000  \n"]}],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","print(data.describe())"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["data[\"datetime\"] = pd.to_datetime(data[\"datetime\"])\n","data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","\n","data = data.sort_values(by=\"datetime\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# data = data.drop(columns = ['is_crm'])\n","# print(data.head())"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["holiday_yn       0\n","pick_rgn2_nm     0\n","rider_cnt        0\n","datetime         0\n","hour_reg         0\n","reg_date         0\n","day_of_reg       0\n","is_rain          0\n","rain_group       0\n","rider_cnt_w_1    0\n","rider_cnt_w_2    0\n","rider_cnt_w_3    0\n","rider_cnt_w_4    0\n","order_cnt_w_1    0\n","group_s          0\n","dtype: int64"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","#print(data.shape) "]},{"cell_type":"code","execution_count":50,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[{"name":"stdout","output_type":"stream","text":["holiday_yn             category\n","pick_rgn2_nm           category\n","rider_cnt               float64\n","datetime         datetime64[ns]\n","hour_reg               category\n","reg_date         datetime64[ns]\n","day_of_reg             category\n","is_rain                category\n","rain_group             category\n","rider_cnt_w_1           float64\n","rider_cnt_w_2           float64\n","rider_cnt_w_3           float64\n","rider_cnt_w_4           float64\n","order_cnt_w_1             int64\n","group_s                category\n","dtype: object\n"]}],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in ['day_of_reg','pick_rgn2_nm', 'hour_reg', 'day_of_reg','rain_group', 'holiday_yn', 'group_s', 'is_rain'] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","# #scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# data[num_vars] = scaler.fit_transform(data[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'hour_reg_9',\n","       'hour_reg_10', 'hour_reg_11', 'hour_reg_12', 'hour_reg_13',\n","       'hour_reg_14', 'hour_reg_15', 'hour_reg_16', 'hour_reg_17',\n","       'hour_reg_18', 'hour_reg_19', 'hour_reg_20', 'hour_reg_21',\n","       'hour_reg_22', 'hour_reg_23', 'is_rain_0', 'is_rain_1', 'holiday_yn_N',\n","       'holiday_yn_Y', 'rider_cnt', 'datetime', 'reg_date', 'rider_cnt_w_1',\n","       'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["df = data.drop(columns = ['group_s','rain_group', 'rider_cnt_w_2', 'rider_cnt_w_3','rider_cnt_w_4'])\n","\n","var = ['day_of_reg', 'hour_reg','is_rain', 'holiday_yn', 'pick_rgn2_nm']\n","encoder = OneHotEncoder()\n","onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","df = pd.concat([onehot, df.drop(columns=var)], axis=1)\n","#print(df.head(3))\n","print(df.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train, test set split"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1290, 29) (1080, 29)\n"]}],"source":["# train_ratio = 0.8\n","# total_samples = df.shape[0]\n","# train_samples = int(train_ratio * total_samples)\n","# df_train = df[:train_samples]\n","# df_test = df[train_samples:]\n","\n","df_train = df[df[\"datetime\"]<= '2023-03-31']\n","df_test = df[df[\"datetime\"] >= '2023-04-01']\n","\n","# print(df_train['reg_date'].min()) #2022-01-29\n","# print(df_test['reg_date'].min()) #2023-02-15\n","\n","# print(df_train['reg_date'].max()) #2023-02-15\n","# print(df_test['reg_date'].max()) #2023-05-21\n","\n","df_train = df_train.drop(columns = ['datetime', 'reg_date'])\n","df_test = df_test.drop(columns = ['datetime', 'reg_date'])\n","print(df_train.shape, df_test.shape) # 126,000, 54375 / 33000 11250 "]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1290, 28) (1290,) (1080, 28) (1080,)\n"]}],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt'])\n","y_train = df_train['rider_cnt']\n","\n","X_test = df_test.drop(columns=['rider_cnt'])\n","y_test = df_test['rider_cnt']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'hour_reg_9',\n","       'hour_reg_10', 'hour_reg_11', 'hour_reg_12', 'hour_reg_13',\n","       'hour_reg_14', 'hour_reg_15', 'hour_reg_16', 'hour_reg_17',\n","       'hour_reg_18', 'hour_reg_19', 'hour_reg_20', 'hour_reg_21',\n","       'hour_reg_22', 'hour_reg_23', 'is_rain_0', 'is_rain_1', 'holiday_yn_N',\n","       'holiday_yn_Y', 'rider_cnt_w_1', 'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### numeric_scale "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 입력 변수 \n","# numeric_cols = ['rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#                 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#                 'order_cnt_w_4']\n","\n","# # scaler \n","# scaler_X = StandardScaler()\n","\n","# # X_train, X_test\n","# X_train_scaled = scaler_X.fit_transform(X_train[numeric_cols])\n","# X_test_scaled = scaler_X.transform(X_test[numeric_cols])\n","\n","# # 스케일링된 결과를 DataFrame으로 변환\n","# X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_cols, index = X_train.index)\n","# X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_cols, index = X_test.index)\n","\n","# # 원래의 범주형 변수들을 선택\n","# categorical_cols = [col for col in X_train.columns if col not in numeric_cols]\n","# X_train_cat = X_train[categorical_cols]\n","# X_test_cat = X_test[categorical_cols]\n","\n","# # 스케일링된 DataFrame과 범주형 변수들을 병합\n","# X_train_final = pd.concat([X_train_scaled, X_train_cat], axis=1)\n","# X_test_final = pd.concat([X_test_scaled, X_test_cat], axis=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측값\n","# y_train, y_test\n","# scaler_y = StandardScaler()\n","# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n","# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n","# y_train_scaled = y_train_scaled.ravel()\n","# y_test_scaled=  y_test_scaled.ravel()\n","\n","# print(y_train_scaled.shape)\n","# print(y_test_scaled.shape)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:              rider_cnt   R-squared:                       0.962\n","Model:                            OLS   Adj. R-squared:                  0.961\n","Method:                 Least Squares   F-statistic:                     1327.\n","Date:                Mon, 12 Jun 2023   Prob (F-statistic):               0.00\n","Time:                        15:02:00   Log-Likelihood:                -6731.3\n","No. Observations:                1290   AIC:                         1.351e+04\n","Df Residuals:                    1265   BIC:                         1.364e+04\n","Df Model:                          24                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================\n","                     coef    std err          t      P>|t|      [0.025      0.975]\n","----------------------------------------------------------------------------------\n","const             89.2843      5.783     15.439      0.000      77.939     100.630\n","day_of_reg_금요일     7.6292      4.452      1.713      0.087      -1.106      16.364\n","day_of_reg_목요일    -4.0560      4.177     -0.971      0.332     -12.251       4.139\n","day_of_reg_수요일   -11.9025      3.767     -3.160      0.002     -19.292      -4.513\n","day_of_reg_월요일   -21.2900      3.744     -5.686      0.000     -28.636     -13.945\n","day_of_reg_일요일    63.5358      6.635      9.576      0.000      50.519      76.553\n","day_of_reg_토요일    67.7306      6.686     10.130      0.000      54.614      80.848\n","day_of_reg_화요일   -12.3627      4.291     -2.881      0.004     -20.782      -3.944\n","hour_reg_9      -144.0592      9.139    -15.763      0.000    -161.989    -126.130\n","hour_reg_10      -40.9103      5.434     -7.528      0.000     -51.571     -30.250\n","hour_reg_11      114.5815      8.470     13.527      0.000      97.964     131.199\n","hour_reg_12      109.3798      7.428     14.725      0.000      94.807     123.952\n","hour_reg_13        9.3978      4.759      1.975      0.049       0.061      18.735\n","hour_reg_14      -48.3342      5.267     -9.176      0.000     -58.668     -38.001\n","hour_reg_15      -57.1022      5.558    -10.273      0.000     -68.007     -46.197\n","hour_reg_16      -27.8602      4.939     -5.641      0.000     -37.550     -18.170\n","hour_reg_17       57.8550      5.838      9.910      0.000      46.401      69.309\n","hour_reg_18      129.5846      8.612     15.047      0.000     112.689     146.480\n","hour_reg_19      136.5734      8.351     16.354      0.000     120.189     152.957\n","hour_reg_20       43.7862      5.259      8.325      0.000      33.468      54.104\n","hour_reg_21      -29.4741      4.915     -5.997      0.000     -39.117     -19.832\n","hour_reg_22      -64.7819      5.726    -11.313      0.000     -76.016     -53.548\n","hour_reg_23      -99.3519      7.055    -14.082      0.000    -113.194     -85.510\n","is_rain_0         65.5476      3.692     17.756      0.000      58.305      72.790\n","is_rain_1         23.7367      4.721      5.028      0.000      14.476      32.998\n","holiday_yn_N      80.5957      4.759     16.934      0.000      71.258      89.933\n","holiday_yn_Y       8.6887      5.567      1.561      0.119      -2.232      19.610\n","rider_cnt_w_1      0.4532      0.035     12.980      0.000       0.385       0.522\n","order_cnt_w_1      0.0596      0.010      6.118      0.000       0.040       0.079\n","==============================================================================\n","Omnibus:                      316.593   Durbin-Watson:                   0.951\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):            15338.920\n","Skew:                          -0.201   Prob(JB):                         0.00\n","Kurtosis:                      19.888   Cond. No.                     2.10e+18\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 7.57e-28. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 선형 회귀 모델 학습\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 잔차 계산\n","y_pred = model.predict(X_test)\n","residuals = y_test - y_pred\n","\n","# 변수별 잔차 그래프 그리기\n","for column in X_test.columns:\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x=X_test[column], y=residuals)\n","    plt.title(f'Residuals vs. {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Residuals')\n","    plt.show()\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["classifier = LGBMRegressor()\n","\n","parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","              {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","grid_search = GridSearchCV(estimator=classifier,\n","                           param_grid=parameters,\n","                           scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","                           cv=10,\n","                           n_jobs=-1,\n","                           refit='neg_mean_squared_error')                     \n","\n","grid_search.fit(X_train, y_train)\n","best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","best_parameters = grid_search.best_params_\n","print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","print(\"Best MAE: {:.2f}\".format(best_mae))\n","print(\"Best Parameters:\", best_parameters)\n","\n","# best rmse : 27,91\n","# best mae : 17.55\n","# Best Parameters: {'learning_rate': 0.075, 'max_depth': 7, 'n_estimators': 50, 'num_leaves': 64}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n","    }\n","\n","    model = LGBMRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n","\n","#Best RMSE: 29.84\n","#Best Parameters: {'learning_rate': 0.03534645154012776, 'n_estimators': 139, 'max_depth': 7, 'num_leaves': 62}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 27.83\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 28.83\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        'min_samples_split': [2, 5, 10],\n","    }\n","\n","    model = RandomForestRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 28.9\n","# Random Forest Regressor Best Parameters:  {'max_depth': 9, 'min_samples_split': 2, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                         cv_rmse  cv_rmse_std  Test RMSE   Test MAE   \n","Lasso                  46.838914    20.372355  50.762135  34.829011  \\\n","LGBMRegressor          45.248152    21.367663  48.069947  33.824103   \n","RandomForestRegressor  43.658116    19.936501  47.276357  32.967397   \n","\n","                       Test MAPE   Test R2  \n","Lasso                   6.343295  0.945687  \n","LGBMRegressor           6.049356  0.951296  \n","RandomForestRegressor   5.970338  0.952890  \n"]}],"source":["train_set = data[data[\"datetime\"] <= '2023-03-31']\n","test_set = data[data[\"datetime\"] >= '2023-04-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate= 0.03534645154012776, max_depth=7, n_estimators=139, num_leaves=62), #, subsample= 0.8, random_state=2345),\n","        RandomForestRegressor(random_state=0, max_depth=9, min_samples_split=2, n_estimators=200),\n","    ]\n","\n","    result_test = pd.DataFrame({'datetime': test_set[\"reg_date\"],\n","                                'pick_rgn2_nm': test_set[\"pick_rgn2_nm\"], 'hour_reg': test_set[\"hour_reg\"], \n","                                'is_rain': test_set[\"is_rain\"], 'day_of_reg': test_set[\"day_of_reg\"], \"holiday_yn\" : test_set[\"holiday_yn\"],\n","                                'y_test': test_set[\"rider_cnt\"]})\n","    \n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        cv_results = cross_validate(reg, X_train, y_train, cv = 10, scoring = scoring)\n","        \n","        # Cross-validation RMSE and SD\n","        cv_rmse = -np.mean(cv_results['test_rmse'])\n","        cv_rmse_std = np.std(cv_results['test_rmse'])\n","\n","        reg.fit(X_train, y_train)\n","        y_pred_test = reg.predict(X_test)\n","        \n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'cv_rmse' : cv_rmse,\n","            'cv_rmse_std' : cv_rmse_std,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","         \n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","             \n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_three = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    average_lgbm_rf = (lgbm_pred+rf_pred) /2 \n","    average_lgbm_la = (lgbm_pred + lasso_pred) /2\n","    average_rf_la = (lasso_pred+rf_pred) / 2\n","\n","    result_test['y_pred_avg_three'] = average_three\n","    result_test['y_pred_avg_lgbm_rf'] = average_lgbm_rf\n","    result_test['y_pred_avg_lgbm_la'] = average_lgbm_la\n","    result_test['y_pred_avg_rf_la'] = average_rf_la\n","\n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_test.to_csv('prediction_results_test_set_w_1.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Calculate MAE, RMSE and MAPE for each model\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","metrics = ['MAE', 'RMSE', 'MAPE']\n","models = ['test_Lasso', 'test_LGBMRegressor', 'test_RandomForestRegressor', 'avg_three', 'avg_lgbm_rf', 'avg_lgbm_la', 'avg_rf_la']\n","\n","results = []\n","\n","for model in models:\n","    y_true = predict['y_test']\n","    y_pred = predict[f'y_pred_{model}']\n","\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    mape = MAPE(y_true, y_pred)\n","\n","    results.append({\n","        'model': model,\n","        'MAE': mae,\n","        'RMSE': rmse,\n","        'MAPE': mape\n","    })\n","\n","result_df = pd.DataFrame(results)\n","print(result_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 세분화하여 MAE 값 확인"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg_three'] = abs(predict['y_pred_avg_three'] - predict['y_test'])\n","predict['MAE_avg_lgbm_rf'] = abs(predict['y_pred_avg_lgbm_rf'] - predict['y_test'])\n","predict['MAE_avg_lgbm_la'] = abs(predict['y_pred_avg_lgbm_la'] - predict['y_test'])\n","predict['MAE_avg_rf_la'] = abs(predict['y_pred_avg_rf_la'] - predict['y_test'])\n","\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['is_rain', 'holiday_yn']).agg({\n","   'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","   'MAE_RandomForestRegressor': np.mean,\n","    'MAE_avg_three' : np.mean,\n","    'MAE_avg_lgbm_rf' : np.mean,\n","    'MAE_avg_lgbm_la' : np.mean,\n","    'MAE_avg_rf_la' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg_three'] = abs(predict['y_pred_avg_three'] - predict['y_test'])\n","predict['MAE_avg_lgbm_rf'] = abs(predict['y_pred_avg_lgbm_rf'] - predict['y_test'])\n","predict['MAE_avg_lgbm_la'] = abs(predict['y_pred_avg_lgbm_la'] - predict['y_test'])\n","predict['MAE_avg_rf_la'] = abs(predict['y_pred_avg_rf_la'] - predict['y_test'])\n","\n","\n","# 'day_of_reg2', 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['group_s']).agg({\n","    'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","    'MAE_avg_three' : np.mean,\n","    'MAE_avg_lgbm_rf' : np.mean,\n","    'MAE_avg_lgbm_la' : np.mean,\n","    'MAE_avg_rf_la' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 세분화하여 MAPE 확인 "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg_three'] = abs((predict['y_pred_avg_three'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_lgbm_rf'] = abs((predict['y_pred_avg_lgbm_rf'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_lgbm_la'] = abs((predict['y_pred_avg_lgbm_la'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_rf_la'] = abs((predict['y_pred_avg_rf_la'] - predict['y_test']) / predict['y_test']) * 100\n","\n","# 'is_rain', 'is_holiday' 별로 차이의 평균 계산\n","result = predict.groupby(['is_rain', 'holiday_yn']).agg({\n","\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","    'MAPE_avg_three' : np.mean,\n","    'MAPE_avg_lgbm_rf' : np.mean,\n","    'MAPE_avg_lgbm_la' : np.mean,\n","    'MAPE_avg_rf_la' : np.mean\n","}).reset_index()\n","\n","print(result)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set.csv', encoding = \"cp949\")\n","\n","\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg_three'] = abs(predict['y_pred_avg_three'] - predict['y_test'])\n","predict['MAE_avg_lgbm_rf'] = abs(predict['y_pred_avg_lgbm_rf'] - predict['y_test'])\n","predict['MAE_avg_lgbm_la'] = abs(predict['y_pred_avg_lgbm_la'] - predict['y_test'])\n","predict['MAE_avg_rf_la'] = abs(predict['y_pred_avg_rf_la'] - predict['y_test'])\n","\n","result = predict.groupby(['hour_reg']).agg({\n","    'MAE_Lasso': np.mean,\n","    'MAE_LGBMRegressor': np.mean,\n","    'MAE_RandomForestRegressor': np.mean,\n","    'MAE_avg_three' : np.mean,\n","    'MAE_avg_lgbm_rf' : np.mean,\n","    'MAE_avg_lgbm_la' : np.mean,\n","    'MAE_avg_rf_la' : np.mean\n","    \n","}).reset_index()\n","\n","print(result)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 변수 중요도 파악 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### permutation importance -> RandomForest, LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    # train set에 대한 permutation importance 계산\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","\n","    # test set에 대한 permutation importance 계산\n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    # importance 값 저장 (numpy array를 list로 변환)\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    # importance 값에 따라 내림차순 정렬\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","\n","    # CSV 파일로 저장\n","    feature_importances.to_csv('feature_importances_lgbm.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","# LGBM 모델을 불러옴\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","\n","# permutation importance 계산\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","#print(scores_df)\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","    \n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","    \n","    feature_importances.to_csv('feature_importances_Rf.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","lgbm_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lasso_model = joblib.load('model_Lasso.joblib')\n","lasso_coef = pd.Series(lasso_model.coef_, index=X_train.columns)\n","selected_feats_lasso = lasso_coef[lasso_coef!=0].index\n","\n","print(\"Number of features selected by Lasso: \", len(selected_feats_lasso))\n","print(\"Features selected by Lasso: \", selected_feats_lasso)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_feature_importances(model, model_name):\n","    importances = model.feature_importances_\n","    feat_names = X_train.columns\n","    feature_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n","\n","    #print(\"Feature importances for \", model_name, \" : \")\n","    #print(feature_imp)\n","\n","    # Creating a bar plot\n","    plt.figure(figsize = (20,15))\n","    sns.barplot(x=feature_imp, y=feature_imp.index)\n","    # Add labels to your graph\n","    plt.xlabel('Feature Importance Score')\n","    plt.ylabel('Features')\n","    plt.title(\"Visualizing Important Features\")\n","    plt.legend()\n","    plt.show()\n","\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","plot_feature_importances(lgbm_model, 'LGBMRegressor')\n","\n","rf_model = joblib.load('model_RandomForestRegressor.joblib')\n","plot_feature_importances(rf_model, 'RandomForestRegressor')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### stacking model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from mlxtend.regressor import StackingCVRegressor\n","from sklearn.linear_model import Lasso, LinearRegression\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.model_selection import cross_val_score\n","\n","# Initialize models\n","lasso = Lasso()\n","lr = LinearRegression()\n","rf = RandomForestRegressor()\n","\n","# Meta model\n","gbr = GradientBoostingRegressor()\n","\n","# Stacking model\n","stack = StackingCVRegressor(regressors=(lasso, lr, rf),\n","                            meta_regressor=gbr,\n","                            use_features_in_secondary=True)\n","\n","# Training the stacking classifier\n","stack.fit(X_train.values, y_train.values)\n","\n","# Predict\n","y_pred = stack.predict(X_test.values)\n","\n","# Evaluate the model\n","print('Stack Test RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)))\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
