{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":42,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import optuna\n","import joblib\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import font_manager\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.inspection import permutation_importance\n","import statsmodels.api as sm \n","from time import time\n","\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# 한글 폰트 경로 설정\n","font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'\n","font_name = font_manager.FontProperties(fname=font_path).get_name()\n","plt.rc('font', family=font_name)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(346, 12)\n"]}],"source":["data = pd.read_csv('combined_data_day.csv', encoding = \"cp949\")\n","data.head()\n","print(data.shape) "]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 346 entries, 0 to 345\n","Data columns (total 12 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   reg_date       346 non-null    object \n"," 1   rider_cnt      346 non-null    int64  \n"," 2   day_of_reg     346 non-null    object \n"," 3   rain_c         346 non-null    float64\n"," 4   snow_c         346 non-null    float64\n"," 5   is_rain        346 non-null    int64  \n"," 6   is_holiday     346 non-null    int64  \n"," 7   rider_cnt_w_1  346 non-null    int64  \n"," 8   rider_cnt_w_2  346 non-null    int64  \n"," 9   rider_cnt_w_3  346 non-null    int64  \n"," 10  rider_cnt_w_4  346 non-null    int64  \n"," 11  order_cnt_w_1  346 non-null    int64  \n","dtypes: float64(2), int64(8), object(2)\n","memory usage: 32.6+ KB\n","None\n"]}],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","#print(data.describe())"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","data = data.sort_values(by=\"reg_date\")"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["data = data.drop(columns = ['rain_c','snow_c'])\n","# print(data.head())"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["reg_date         0\n","rider_cnt        0\n","day_of_reg       0\n","is_rain          0\n","is_holiday       0\n","rider_cnt_w_1    0\n","rider_cnt_w_2    0\n","rider_cnt_w_3    0\n","rider_cnt_w_4    0\n","order_cnt_w_1    0\n","dtype: int64"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["#data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","#print(data.shape) "]},{"cell_type":"code","execution_count":49,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[{"name":"stdout","output_type":"stream","text":["reg_date         datetime64[ns]\n","rider_cnt                 int64\n","day_of_reg             category\n","is_rain                category\n","is_holiday             category\n","rider_cnt_w_1             int64\n","rider_cnt_w_2             int64\n","rider_cnt_w_3             int64\n","rider_cnt_w_4             int64\n","order_cnt_w_1             int64\n","dtype: object\n"]}],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in [ 'day_of_reg', 'is_rain','is_holiday' ] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","# #scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# data[num_vars] = scaler.fit_transform(data[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'is_rain_0',\n","       'is_rain_1', 'is_holiday_0', 'is_holiday_1', 'reg_date', 'rider_cnt',\n","       'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3', 'rider_cnt_w_4',\n","       'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["#df = data.drop(columns = ['month'])\n","df = data\n","var = [ 'day_of_reg', 'is_rain','is_holiday' ]\n","encoder = OneHotEncoder()\n","onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","df = pd.concat([onehot, df.drop(columns=var)], axis=1)\n","\n","print(df.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train, test set split"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(272, 17) (73, 17)\n"]}],"source":["# train_ratio = 0.8\n","# total_samples = df.shape[0]\n","# train_samples = int(train_ratio * total_samples)\n","# df_train = df[:train_samples]\n","# df_test = df[train_samples:]\n","\n","df_train = df[df[\"reg_date\"]<= '2023-03-30']\n","df_test = df[df[\"reg_date\"] >= '2023-04-01']\n","\n","# print(df_train['reg_date'].min()) #2022-01-29\n","# print(df_test['reg_date'].min()) #2023-02-15\n","\n","# print(df_train['reg_date'].max()) #2023-02-15\n","# print(df_test['reg_date'].max()) #2023-05-21\n","\n","df_train = df_train.drop(columns = ['reg_date'])\n","df_test = df_test.drop(columns = ['reg_date'])\n","print(df_train.shape, df_test.shape) # 272,74\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(272, 16) (272,) (73, 16) (73,)\n"]}],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt'])\n","y_train = df_train['rider_cnt']\n","\n","X_test = df_test.drop(columns=['rider_cnt'])\n","y_test = df_test['rider_cnt']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape) #272, 73 "]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'is_rain_0',\n","       'is_rain_1', 'is_holiday_0', 'is_holiday_1', 'rider_cnt_w_1',\n","       'rider_cnt_w_2', 'rider_cnt_w_3', 'rider_cnt_w_4', 'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### numeric_scale "]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["# # 입력 변수 \n","# numeric_cols = ['rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#                 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#                 'order_cnt_w_4']\n","\n","# # scaler \n","# scaler_X = StandardScaler()\n","\n","# # X_train, X_test\n","# X_train_scaled = scaler_X.fit_transform(X_train[numeric_cols])\n","# X_test_scaled = scaler_X.transform(X_test[numeric_cols])\n","\n","# # 스케일링된 결과를 DataFrame으로 변환\n","# X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_cols, index = X_train.index)\n","# X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_cols, index = X_test.index)\n","\n","# # 원래의 범주형 변수들을 선택\n","# categorical_cols = [col for col in X_train.columns if col not in numeric_cols]\n","# X_train_cat = X_train[categorical_cols]\n","# X_test_cat = X_test[categorical_cols]\n","\n","# # 스케일링된 DataFrame과 범주형 변수들을 병합\n","# X_train_final = pd.concat([X_train_scaled, X_train_cat], axis=1)\n","# X_test_final = pd.concat([X_test_scaled, X_test_cat], axis=1)\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["# 예측값\n","# y_train, y_test\n","# scaler_y = StandardScaler()\n","# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n","# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n","# y_train_scaled = y_train_scaled.ravel()\n","# y_test_scaled=  y_test_scaled.ravel()\n","\n","# print(y_train_scaled.shape)\n","# print(y_test_scaled.shape)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:              rider_cnt   R-squared:                       0.430\n","Model:                            OLS   Adj. R-squared:                  0.401\n","Method:                 Least Squares   F-statistic:                     14.96\n","Date:                Tue, 13 Jun 2023   Prob (F-statistic):           5.54e-25\n","Time:                        13:43:31   Log-Likelihood:                -2213.5\n","No. Observations:                 272   AIC:                             4455.\n","Df Residuals:                     258   BIC:                             4505.\n","Df Model:                          13                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================\n","                     coef    std err          t      P>|t|      [0.025      0.975]\n","----------------------------------------------------------------------------------\n","const           9033.8115   1029.643      8.774      0.000    7006.238    1.11e+04\n","day_of_reg_금요일  2165.4533    275.429      7.862      0.000    1623.078    2707.829\n","day_of_reg_목요일   749.7183    161.394      4.645      0.000     431.902    1067.535\n","day_of_reg_수요일   530.9842    145.636      3.646      0.000     244.198     817.770\n","day_of_reg_월요일   616.7265    148.772      4.145      0.000     323.765     909.688\n","day_of_reg_일요일  1787.5885    295.751      6.044      0.000    1205.195    2369.982\n","day_of_reg_토요일  2391.7592    330.420      7.239      0.000    1741.096    3042.422\n","day_of_reg_화요일   791.5816    166.464      4.755      0.000     463.780    1119.383\n","is_rain_0       4885.8229    555.901      8.789      0.000    3791.142    5980.504\n","is_rain_1       4147.9886    480.654      8.630      0.000    3201.485    5094.492\n","is_holiday_0    4929.6710    523.986      9.408      0.000    3897.836    5961.506\n","is_holiday_1    4104.1405    531.492      7.722      0.000    3057.525    5150.756\n","rider_cnt_w_1     -0.1227      0.077     -1.591      0.113      -0.275       0.029\n","rider_cnt_w_2     -0.0813      0.063     -1.282      0.201      -0.206       0.044\n","rider_cnt_w_3     -0.0019      0.064     -0.029      0.977      -0.128       0.124\n","rider_cnt_w_4     -0.0572      0.064     -0.888      0.375      -0.184       0.070\n","order_cnt_w_1      0.0032      0.004      0.910      0.363      -0.004       0.010\n","==============================================================================\n","Omnibus:                      119.203   Durbin-Watson:                   1.471\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):              889.756\n","Skew:                          -1.583   Prob(JB):                    6.19e-194\n","Kurtosis:                      11.276   Cond. No.                     1.08e+21\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 1.33e-29. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 선형 회귀 모델 학습\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 잔차 계산\n","y_pred = model.predict(X_test)\n","residuals = y_test - y_pred\n","\n","# 변수별 잔차 그래프 그리기\n","for column in X_test.columns:\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x=X_test[column], y=residuals)\n","    plt.title(f'Residuals vs. {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Residuals')\n","    plt.show()\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[],"source":["# classifier = LGBMRegressor()\n","\n","# parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","#               {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","# grid_search = GridSearchCV(estimator=classifier,\n","#                            param_grid=parameters,\n","#                            scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","#                            cv=10,\n","#                            n_jobs=-1,\n","#                            refit='neg_mean_squared_error')                     \n","\n","# grid_search.fit(X_train, y_train)\n","# best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","# best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","# best_parameters = grid_search.best_params_\n","# print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","# print(\"Best MAE: {:.2f}\".format(best_mae))\n","# print(\"Best Parameters:\", best_parameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n","    }\n","\n","    model = LGBMRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n","\n","#Best RMSE: 29.84\n","#Best Parameters:  {'learning_rate': 0.02546270038894073, 'n_estimators': 76, 'max_depth': 5, 'num_leaves': 56}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ridge Best RMSE: 892.47\n","Ridge Best Parameters:  {'alpha': 1.0}\n"]}],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 27.83\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Lasso Best RMSE: 892.98\n","Lasso Best Parameters:  {'alpha': 0.1}\n"]}],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 28.83\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        'min_samples_split': [2, 5, 10],\n","    }\n","\n","    model = RandomForestRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 28.9\n","# Random Forest Regressor Best Parameters:  {'max_depth': 9, 'min_samples_split': 2, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                          cv_rmse  cv_rmse_std   Test RMSE    Test MAE   \n","LinearRegression       843.504698   225.185909  890.594163  680.275733  \\\n","Lasso                  843.422646   225.309968  889.707672  679.506381   \n","LGBMRegressor          908.930007   243.307143  812.717502  624.858264   \n","RandomForestRegressor  856.007120   230.879960  847.374670  662.600032   \n","\n","                       Test MAPE   Test R2  \n","LinearRegression        4.109894  0.163696  \n","Lasso                   4.105164  0.165360  \n","LGBMRegressor           3.750243  0.303560  \n","RandomForestRegressor   3.964201  0.242896  \n"]}],"source":["train_set = data[data[\"reg_date\"] <= '2023-03-30']\n","test_set = data[data[\"reg_date\"]  >= '2023-04-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        LinearRegression(),\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate = 0.02546270038894073, n_estimators =  76, max_depth = 5, num_leaves = 56),\n","        RandomForestRegressor(random_state=0, max_depth=9, min_samples_split=2, n_estimators=200),\n","    \n","    ]\n","\n","    result_test = pd.DataFrame({'reg_date': test_set[\"reg_date\"], 'day_of_reg': test_set[\"day_of_reg\"], \n","                                'is_rain' : test_set[\"is_rain\"],\n","                                'is_holiday': test_set[\"is_holiday\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        cv_results = cross_validate(reg, X_train, y_train, cv = 5, scoring = scoring)\n","        \n","        cv_rmse = -np.mean(cv_results['test_rmse'])\n","        cv_rmse_std = np.std(cv_results['test_rmse'])\n","        \n","        reg.fit(X_train, y_train)\n","        y_pred_test = reg.predict(X_test)\n","        \n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'cv_rmse' : cv_rmse,\n","            'cv_rmse_std' : cv_rmse_std,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","        \n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","             \n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_three = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    average_lgbm_rf = (lgbm_pred+rf_pred) /2 \n","    average_lgbm_la = (lgbm_pred + lasso_pred) /2\n","    average_rf_la = (lasso_pred+rf_pred) / 2\n","\n","    result_test['y_pred_avg_three'] = average_three\n","    result_test['y_pred_avg_lgbm_rf'] = average_lgbm_rf\n","    result_test['y_pred_avg_lgbm_la'] = average_lgbm_la\n","    result_test['y_pred_avg_rf_la'] = average_rf_la\n","    \n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_test.to_csv('prediction_results_test_set_day.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 모델별 비교"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                        model         MAE        RMSE      MAPE\n","0       test_LinearRegression  680.275733  890.594163  4.109894\n","1                  test_Lasso  679.506381  889.707672  4.105164\n","2          test_LGBMRegressor  624.858264  812.717502  3.750243\n","3  test_RandomForestRegressor  662.600032  847.374670  3.964201\n","4                   avg_three  623.107568  810.871656  3.741051\n","5                 avg_lgbm_rf  634.691477  815.569258  3.801802\n","6                 avg_lgbm_la  621.564241  814.016196  3.740990\n","7                   avg_rf_la  638.334895  833.163634  3.835391\n"]}],"source":["# Calculate MAE, RMSE and MAPE for each model\n","predict = pd.read_csv('prediction_results_test_set_day.csv', encoding = \"cp949\")\n","\n","metrics = ['MAE', 'RMSE', 'MAPE']\n","models = ['test_LinearRegression','test_Lasso', 'test_LGBMRegressor', 'test_RandomForestRegressor', 'avg_three', 'avg_lgbm_rf', 'avg_lgbm_la', 'avg_rf_la']\n","\n","results = []\n","\n","for model in models:\n","    y_true = predict['y_test']\n","    y_pred = predict[f'y_pred_{model}']\n","\n","    mae = mean_absolute_error(y_true, y_pred)\n","    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n","    mape = MAPE(y_true, y_pred)\n","\n","    results.append({\n","        'model': model,\n","        'MAE': mae,\n","        'RMSE': rmse,\n","        'MAPE': mape\n","    })\n","\n","result_df = pd.DataFrame(results)\n","print(result_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### MAPE 모델별 비교"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### RMSE 모델 비교 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 변수 중요도 파악 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### permutation importance -> RandomForest, LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    # train set에 대한 permutation importance 계산\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","\n","    # test set에 대한 permutation importance 계산\n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    # importance 값 저장 (numpy array를 list로 변환)\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    # importance 값에 따라 내림차순 정렬\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","\n","    # CSV 파일로 저장\n","    feature_importances.to_csv('feature_importances_lgbm.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","# LGBM 모델을 불러옴\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","\n","# permutation importance 계산\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","#print(scores_df)\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","    \n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","    \n","    feature_importances.to_csv('feature_importances_Rf.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","lgbm_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lasso_model = joblib.load('model_Lasso.joblib')\n","lasso_coef = pd.Series(lasso_model.coef_, index=X_train.columns)\n","selected_feats_lasso = lasso_coef[lasso_coef!=0].index\n","\n","print(\"Number of features selected by Lasso: \", len(selected_feats_lasso))\n","print(\"Features selected by Lasso: \", selected_feats_lasso)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_feature_importances(model, model_name):\n","    importances = model.feature_importances_\n","    feat_names = X_train.columns\n","    feature_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n","\n","    #print(\"Feature importances for \", model_name, \" : \")\n","    #print(feature_imp)\n","\n","    # Creating a bar plot\n","    plt.figure(figsize = (20,15))\n","    sns.barplot(x=feature_imp, y=feature_imp.index)\n","    # Add labels to your graph\n","    plt.xlabel('Feature Importance Score')\n","    plt.ylabel('Features')\n","    plt.title(\"Visualizing Important Features\")\n","    plt.legend()\n","    plt.show()\n","\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","plot_feature_importances(lgbm_model, 'LGBMRegressor')\n","\n","rf_model = joblib.load('model_RandomForestRegressor.joblib')\n","plot_feature_importances(rf_model, 'RandomForestRegressor')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
