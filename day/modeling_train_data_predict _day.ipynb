{"cells":[{"cell_type":"markdown","metadata":{"id":"9WtJa1_baHGy"},"source":["# 1. dataset "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"L0_lp9Gw3Hzz"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time \n","import optuna\n","import joblib\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib import font_manager\n","\n","# sklearn 관련\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import Ridge, Lasso\n","from sklearn.svm import SVR\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n","from sklearn.inspection import permutation_importance\n","import statsmodels.api as sm \n","from time import time\n","\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Categorical, Integer\n","\n","\n","# 전처리 \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from imblearn.over_sampling import SMOTE\n","\n","# lightgbm 관련\n","from lightgbm import LGBMRegressor\n","from lightgbm import plot_importance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 한글 폰트 경로 설정\n","font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'\n","font_name = font_manager.FontProperties(fname=font_path).get_name()\n","plt.rc('font', family=font_name)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"wiznMj624cML","outputId":"4eb9fb8c-1b16-4c4d-da6c-50a14f1386e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["(352, 12)\n"]}],"source":["data = pd.read_csv('combined_data_day.csv', encoding = \"cp949\")\n","data.head()\n","print(data.shape) #352"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1667535439970,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"bF6xHQOlmtf0","outputId":"2ec09ef7-5d5d-4127-bf7c-e5d33e018848"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 352 entries, 0 to 351\n","Data columns (total 12 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   reg_date       352 non-null    object \n"," 1   holiday_yn     352 non-null    object \n"," 2   rider_cnt      352 non-null    int64  \n"," 3   day_of_reg     352 non-null    object \n"," 4   rain_c         352 non-null    float64\n"," 5   snow_c         352 non-null    float64\n"," 6   is_rain        352 non-null    int64  \n"," 7   rider_cnt_w_1  352 non-null    int64  \n"," 8   rider_cnt_w_2  352 non-null    int64  \n"," 9   rider_cnt_w_3  352 non-null    int64  \n"," 10  rider_cnt_w_4  352 non-null    int64  \n"," 11  order_cnt_w_1  352 non-null    int64  \n","dtypes: float64(2), int64(7), object(3)\n","memory usage: 33.1+ KB\n","None\n","          rider_cnt      rain_c      snow_c     is_rain  rider_cnt_w_1   \n","count    352.000000  352.000000  352.000000  352.000000     352.000000  \\\n","mean   16314.150568    5.401136    0.124432    0.312500   16307.252841   \n","std     1078.457967   19.402351    0.580720    0.464172    1058.102234   \n","min    11416.000000    0.000000    0.000000    0.000000   11416.000000   \n","25%    15752.250000    0.000000    0.000000    0.000000   15755.750000   \n","50%    16254.500000    0.000000    0.000000    0.000000   16247.500000   \n","75%    17081.750000    0.125000    0.000000    1.000000   17081.750000   \n","max    19256.000000  176.200000    4.500000    1.000000   19256.000000   \n","\n","       rider_cnt_w_2  rider_cnt_w_3  rider_cnt_w_4  order_cnt_w_1  \n","count      352.00000     352.000000     352.000000     352.000000  \n","mean     16304.93750   16307.133523   16303.676136  232612.056818  \n","std       1051.60748    1046.141782    1042.419910   37516.343073  \n","min      11416.00000   11416.000000   11416.000000  160652.000000  \n","25%      15755.75000   15752.250000   15742.750000  202734.500000  \n","50%      16247.50000   16230.500000   16218.000000  220386.000000  \n","75%      17081.75000   17081.750000   17081.750000  272654.000000  \n","max      19256.00000   19256.000000   19256.000000  328300.000000  \n"]}],"source":["# Checking for null values\n","print(data.info())\n","\n","# Checking for outliers\n","print(data.describe())"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["data[\"reg_date\"] = pd.to_datetime(data[\"reg_date\"])\n","data = data.sort_values(by=\"reg_date\")"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["data = data.drop(columns = ['rain_c','snow_c'])\n","# print(data.head())"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["reg_date         0\n","holiday_yn       0\n","rider_cnt        0\n","day_of_reg       0\n","is_rain          0\n","rider_cnt_w_1    0\n","rider_cnt_w_2    0\n","rider_cnt_w_3    0\n","rider_cnt_w_4    0\n","order_cnt_w_1    0\n","dtype: int64"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["#data = data.dropna(subset=['rider_cnt_w_4'])\n","data.isna().sum()\n","#print(data.shape) "]},{"cell_type":"code","execution_count":30,"metadata":{"id":"a0WNWR6UJvEc"},"outputs":[{"name":"stdout","output_type":"stream","text":["reg_date         datetime64[ns]\n","holiday_yn             category\n","rider_cnt                 int64\n","day_of_reg             category\n","is_rain                category\n","rider_cnt_w_1             int64\n","rider_cnt_w_2             int64\n","rider_cnt_w_3             int64\n","rider_cnt_w_4             int64\n","order_cnt_w_1             int64\n","dtype: object\n"]}],"source":["# category  - pick_rgn2_nm, hour_reg, day_of_reg, is_rain, month, week, is_holiday\n","for col in [ 'day_of_reg', 'is_rain','holiday_yn' ] : \n","    data[col] = data[col].astype('category')\n","\n","print(data.dtypes)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 전처리"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# numeric 변수 scale \n","# scaler = StandardScaler()  #평균 0 , 분산 1로 조정\n","# #scaler = MinMaxScaler()\n","\n","# num_vars = ['rider_cnt_2', 'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#             'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#             'order_cnt_w_4']\n","# data[num_vars] = scaler.fit_transform(data[num_vars])\n","\n","# print(df.head(3))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2-1. one-hot-encoding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n","# X = np.array(ct.fit_transform(X))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'is_rain_0',\n","       'is_rain_1', 'holiday_yn_N', 'holiday_yn_Y', 'reg_date', 'rider_cnt',\n","       'rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3', 'rider_cnt_w_4',\n","       'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["#df = data.drop(columns = ['month'])\n","df = data\n","var = [ 'day_of_reg', 'is_rain','holiday_yn' ]\n","encoder = OneHotEncoder()\n","onehot = pd.DataFrame(encoder.fit_transform(data[var]).toarray(), columns=encoder.get_feature_names_out(var), index = data.index)\n","df = pd.concat([onehot, df.drop(columns=var)], axis=1)\n","\n","print(df.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. train, test set split"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(284, 17) (68, 17)\n"]}],"source":["# train_ratio = 0.8\n","# total_samples = df.shape[0]\n","# train_samples = int(train_ratio * total_samples)\n","# df_train = df[:train_samples]\n","# df_test = df[train_samples:]\n","\n","df_train = df[df[\"reg_date\"]<= '2023-03-31']\n","df_test = df[df[\"reg_date\"] >= '2023-04-01']\n","\n","# print(df_train['reg_date'].min()) #2022-01-29\n","# print(df_test['reg_date'].min()) #2023-02-15\n","\n","# print(df_train['reg_date'].max()) #2023-02-15\n","# print(df_test['reg_date'].max()) #2023-05-21\n","\n","df_train = df_train.drop(columns = ['reg_date'])\n","df_test = df_test.drop(columns = ['reg_date'])\n","print(df_train.shape, df_test.shape) # 289, 67\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(284, 16) (284,) (68, 16) (68,)\n"]}],"source":["# X_train, y_train 나누기\n"," \n","# X_train = train.iloc[:, :-1]\n","# y_train = df_train.iloc[:, -1]\n","\n","# X_test = df_test.iloc[:, :-1]\n","# y_test = df_test.iloc[:, -1]\n","\n","X_train = df_train.drop(columns=['rider_cnt'])\n","y_train = df_train['rider_cnt']\n","\n","X_test = df_test.drop(columns=['rider_cnt'])\n","y_test = df_test['rider_cnt']\n","\n","print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['day_of_reg_금요일', 'day_of_reg_목요일', 'day_of_reg_수요일', 'day_of_reg_월요일',\n","       'day_of_reg_일요일', 'day_of_reg_토요일', 'day_of_reg_화요일', 'is_rain_0',\n","       'is_rain_1', 'holiday_yn_N', 'holiday_yn_Y', 'rider_cnt_w_1',\n","       'rider_cnt_w_2', 'rider_cnt_w_3', 'rider_cnt_w_4', 'order_cnt_w_1'],\n","      dtype='object')\n"]}],"source":["print(X_train.columns)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### numeric_scale "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 입력 변수 \n","# numeric_cols = ['rider_cnt_w_1', 'rider_cnt_w_2', 'rider_cnt_w_3',\n","#                 'rider_cnt_w_4', 'order_cnt_w_1', 'order_cnt_w_2', 'order_cnt_w_3',\n","#                 'order_cnt_w_4']\n","\n","# # scaler \n","# scaler_X = StandardScaler()\n","\n","# # X_train, X_test\n","# X_train_scaled = scaler_X.fit_transform(X_train[numeric_cols])\n","# X_test_scaled = scaler_X.transform(X_test[numeric_cols])\n","\n","# # 스케일링된 결과를 DataFrame으로 변환\n","# X_train_scaled = pd.DataFrame(X_train_scaled, columns=numeric_cols, index = X_train.index)\n","# X_test_scaled = pd.DataFrame(X_test_scaled, columns=numeric_cols, index = X_test.index)\n","\n","# # 원래의 범주형 변수들을 선택\n","# categorical_cols = [col for col in X_train.columns if col not in numeric_cols]\n","# X_train_cat = X_train[categorical_cols]\n","# X_test_cat = X_test[categorical_cols]\n","\n","# # 스케일링된 DataFrame과 범주형 변수들을 병합\n","# X_train_final = pd.concat([X_train_scaled, X_train_cat], axis=1)\n","# X_test_final = pd.concat([X_test_scaled, X_test_cat], axis=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 예측값\n","# y_train, y_test\n","# scaler_y = StandardScaler()\n","# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n","# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n","# y_train_scaled = y_train_scaled.ravel()\n","# y_test_scaled=  y_test_scaled.ravel()\n","\n","# print(y_train_scaled.shape)\n","# print(y_test_scaled.shape)"]},{"cell_type":"markdown","metadata":{"id":"QlpNCXbbaTAN"},"source":["# 3. regression - benchmark model"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1667535441557,"user":{"displayName":"노윤지","userId":"04615442591012650407"},"user_tz":-540},"id":"Bv5Jxq3pjKIB","outputId":"5b60db58-31b4-4684-a5f0-9174bc50cbde"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:              rider_cnt   R-squared:                       0.416\n","Model:                            OLS   Adj. R-squared:                  0.388\n","Method:                 Least Squares   F-statistic:                     14.79\n","Date:                Thu, 08 Jun 2023   Prob (F-statistic):           5.29e-25\n","Time:                        11:22:56   Log-Likelihood:                -2316.6\n","No. Observations:                 284   AIC:                             4661.\n","Df Residuals:                     270   BIC:                             4712.\n","Df Model:                          13                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================\n","                     coef    std err          t      P>|t|      [0.025      0.975]\n","----------------------------------------------------------------------------------\n","const           8977.6301   1004.834      8.934      0.000    6999.324     1.1e+04\n","day_of_reg_금요일  2091.6240    289.863      7.216      0.000    1520.945    2662.303\n","day_of_reg_목요일   667.7919    193.944      3.443      0.001     285.958    1049.626\n","day_of_reg_수요일   490.5461    172.480      2.844      0.005     150.968     830.124\n","day_of_reg_월요일   516.6815    171.441      3.014      0.003     179.151     854.212\n","day_of_reg_일요일  1909.2163    381.414      5.006      0.000    1158.292    2660.141\n","day_of_reg_토요일  2543.4107    408.722      6.223      0.000    1738.723    3348.098\n","day_of_reg_화요일   758.3596    196.781      3.854      0.000     370.939    1145.780\n","is_rain_0       4852.7126    539.253      8.999      0.000    3791.037    5914.389\n","is_rain_1       4124.9174    472.242      8.735      0.000    3195.172    5054.662\n","holiday_yn_N    4599.1873    529.614      8.684      0.000    3556.488    5641.886\n","holiday_yn_Y    4378.4428    540.681      8.098      0.000    3313.957    5442.929\n","rider_cnt_w_1     -0.0949      0.075     -1.259      0.209      -0.243       0.054\n","rider_cnt_w_2     -0.0773      0.063     -1.219      0.224      -0.202       0.048\n","rider_cnt_w_3     -0.0148      0.063     -0.233      0.816      -0.140       0.110\n","rider_cnt_w_4     -0.0379      0.064     -0.589      0.557      -0.165       0.089\n","order_cnt_w_1      0.0024      0.003      0.727      0.468      -0.004       0.009\n","==============================================================================\n","Omnibus:                      163.649   Durbin-Watson:                   1.340\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1437.889\n","Skew:                          -2.202   Prob(JB):                         0.00\n","Kurtosis:                      13.106   Cond. No.                     1.94e+23\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 4.24e-34. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"source":["X_train_lm = sm.add_constant(X_train)\n","\n","lr_1 = sm.OLS(y_train, X_train_lm).fit()\n","\n","print(lr_1.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 선형 회귀 모델 학습\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# 잔차 계산\n","y_pred = model.predict(X_test)\n","residuals = y_test - y_pred\n","\n","# 변수별 잔차 그래프 그리기\n","for column in X_test.columns:\n","    plt.figure(figsize=(10,6))\n","    sns.scatterplot(x=X_test[column], y=residuals)\n","    plt.title(f'Residuals vs. {column}')\n","    plt.xlabel(column)\n","    plt.ylabel('Residuals')\n","    plt.show()\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xMBhKvuytrCf"},"source":["# 4.Machine Learning Modeling"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-1. 하이퍼파라미터 튜닝 - Grid Search "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. LightGBM model "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# classifier = LGBMRegressor()\n","\n","# parameters = [{'learning_rate': [0.1, 0.05, 0.01, 0.005], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7]},\n","#               {'learning_rate': [0.15, 0.125, 0.1, 0.075], 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'num_leaves': [16, 32, 64]}]\n","\n","# grid_search = GridSearchCV(estimator=classifier,\n","#                            param_grid=parameters,\n","#                            scoring=['neg_mean_squared_error', 'neg_mean_absolute_error'],\n","#                            cv=10,\n","#                            n_jobs=-1,\n","#                            refit='neg_mean_squared_error')                     \n","\n","# grid_search.fit(X_train, y_train)\n","# best_rmse = np.sqrt(-1 * grid_search.cv_results_['mean_test_neg_mean_squared_error'][grid_search.best_index_])\n","# best_mae = -1 * grid_search.cv_results_['mean_test_neg_mean_absolute_error'][grid_search.best_index_]\n","# best_parameters = grid_search.best_params_\n","# print(\"Best RMSE: {:.2f}\".format(best_rmse))\n","# print(\"Best MAE: {:.2f}\".format(best_mae))\n","# print(\"Best Parameters:\", best_parameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.2),\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 64),\n","    }\n","\n","    model = LGBMRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n","\n","#Best RMSE: 29.84\n","#Best Parameters:  {'learning_rate': 0.02546270038894073, 'n_estimators': 76, 'max_depth': 5, 'num_leaves': 56}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### b. ridge regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Ridge Regression\n","ridge = Ridge()\n","ridge_param_grid = {'alpha': [0.1, 1.0, 2.0, 5.0, 10.0]}\n","ridge_grid_search = GridSearchCV(estimator=ridge, param_grid=ridge_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","ridge_grid_search.fit(X_train, y_train)\n","print(\"Ridge Best RMSE: {:.2f}\".format(np.sqrt(-ridge_grid_search.best_score_)))\n","print(\"Ridge Best Parameters: \", ridge_grid_search.best_params_)\n","\n","# Ridge Best RMSE: 27.83\n","# Ridge Best Parameters:  {'alpha': 10.0}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### c. Lasso regression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Lasso Regression\n","lasso = Lasso(max_iter = 10000)\n","lasso_param_grid = {'alpha': [0.1, 1.0,2.0, 5.0, 10.0]}\n","lasso_grid_search = GridSearchCV(estimator=lasso, param_grid=lasso_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","lasso_grid_search.fit(X_train, y_train)\n","print(\"Lasso Best RMSE: {:.2f}\".format(np.sqrt(-lasso_grid_search.best_score_)))\n","print(\"Lasso Best Parameters: \", lasso_grid_search.best_params_)\n","\n","# Lasso Best RMSE: 28.83\n","# Lasso Best Parameters:  {'alpha': 0.1}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### d. Support vector regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# SVR\n","# svr = SVR()\n","# svr_param_grid = {'kernel': ['rbf', 'linear', 'poly', 'sigmoid'], 'C': [0.1, 1.0, 10.0], 'gamma': ['scale', 'auto']}\n","# svr_grid_search = GridSearchCV(estimator=svr, param_grid=svr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","# svr_grid_search.fit(df_X, df_y)\n","# print(\"SVR Best RMSE: {:.2f}\".format(np.sqrt(-svr_grid_search.best_score_)))\n","# print(\"SVR Best Parameters: \", svr_grid_search.best_params_)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### e. Random Forest Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def objective(trial):\n","    params = {\n","        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n","        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n","        'min_samples_split': [2, 5, 10],\n","    }\n","\n","    model = RandomForestRegressor(**params)\n","    \n","    score = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n","    rmse = np.sqrt(-1 * np.mean(score))\n","\n","    return rmse\n","\n","study = optuna.create_study(direction=\"minimize\")\n","study.optimize(objective, n_trials=50)\n","\n","print(\"Best RMSE: {:.2f}\".format(study.best_value))\n","print(\"Best Parameters:\", study.best_params)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Random Forest Regressor\n","rfr = RandomForestRegressor(random_state=0)\n","rfr_param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, 9], 'min_samples_split': [2, 5, 10]}\n","rfr_grid_search = GridSearchCV(estimator=rfr, param_grid=rfr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","rfr_grid_search.fit(X_train, y_train)\n","print(\"Random Forest Regressor Best RMSE: {:.2f}\".format(np.sqrt(-rfr_grid_search.best_score_)))\n","print(\"Random Forest Regressor Best Parameters: \", rfr_grid_search.best_params_)\n","\n","# Random Forest Regressor Best RMSE: 28.9\n","# Random Forest Regressor Best Parameters:  {'max_depth': 9, 'min_samples_split': 2, 'n_estimators': 200}\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### f. Decision Tree Regressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Decision Tree Regressor\n","dtr = DecisionTreeRegressor(random_state=0)\n","dtr_param_grid = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10]}\n","dtr_grid_search = GridSearchCV(estimator=dtr, param_grid=dtr_param_grid, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n","dtr_grid_search.fit(X_train, y_train)\n","print(\"Decision Tree Regressor Best RMSE: {:.2f}\".format(np.sqrt(-dtr_grid_search.best_score_)))\n","print(\"Decision Tree Regressor Best Parameters: \", dtr_grid_search.best_params_)\n","\n","# Decision Tree Regressor Best RMSE: 27.85\n","# Decision Tree Regressor Best Parameters:  {'max_depth': 7, 'min_samples_split': 2}"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4-2. train, test set 적용 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### a. train, test rmse, mae"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def MAPE(y_test, y_pred):\n","    return np.mean(np.abs((y_test - y_pred) /y_test)) *100"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                          cv_rmse  cv_rmse_std   Test RMSE    Test MAE   \n","LinearRegression       853.072271   239.626638  786.546614  614.769712  \\\n","Lasso                  852.803157   239.897717  785.201487  613.665010   \n","LGBMRegressor          906.323730   235.837656  791.607392  601.192139   \n","RandomForestRegressor  920.137535   230.636252  816.143654  631.095944   \n","\n","                       Test MAPE   Test R2  \n","LinearRegression        3.741362  0.315393  \n","Lasso                   3.734612  0.317733  \n","LGBMRegressor           3.618362  0.306555  \n","RandomForestRegressor   3.791393  0.262902  \n"]}],"source":["train_set = data[data[\"reg_date\"] <= '2023-03-31']\n","test_set = data[data[\"reg_date\"]  >= '2023-04-01']\n","\n","def execute_pipeline(X_train, y_train, X_test, y_test):\n","    regressors = [\n","        LinearRegression(),\n","        Lasso(alpha=0.1, max_iter=5000),\n","        LGBMRegressor(learning_rate = 0.02546270038894073, n_estimators =  76, max_depth = 5, num_leaves = 56),\n","        RandomForestRegressor(random_state=0, max_depth=9, min_samples_split=2, n_estimators=200),\n","    \n","    ]\n","\n","    result_test = pd.DataFrame({'reg_date': test_set[\"reg_date\"], 'day_of_reg': test_set[\"day_of_reg\"], \n","                                'holiday_yn': test_set[\"holiday_yn\"], 'y_test': test_set[\"rider_cnt\"]})\n","    \n","    scores = {}\n","    predictions = {}\n","\n","    for reg in regressors:\n","        reg_name = reg.__class__.__name__\n","        scoring = {\n","            'rmse' : 'neg_root_mean_squared_error',\n","            'mae' : 'neg_mean_absolute_error',\n","            'r2' : 'r2'\n","        } \n","        \n","        cv_results = cross_validate(reg, X_train, y_train, cv = 5, scoring = scoring)\n","        \n","        cv_rmse = -np.mean(cv_results['test_rmse'])\n","        cv_rmse_std = np.std(cv_results['test_rmse'])\n","        \n","        reg.fit(X_train, y_train)\n","        y_pred_test = reg.predict(X_test)\n","        \n","        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n","        mae_test = mean_absolute_error(y_test, y_pred_test)\n","        mape_test = MAPE(y_test, y_pred_test)\n","        r2_test = r2_score(y_test, y_pred_test)\n","\n","        # 모델 저장\n","        model_file = f'model_{reg_name}.joblib'\n","        joblib.dump(reg, model_file)\n","\n","        scores[reg_name] = {\n","            'cv_rmse' : cv_rmse,\n","            'cv_rmse_std' : cv_rmse_std,\n","            'Test RMSE': rmse_test,\n","            'Test MAE': mae_test,\n","            'Test MAPE': mape_test,\n","            'Test R2': r2_test\n","        }\n","        \n","        result_test[f'y_pred_test_{reg_name}'] = y_pred_test\n","             \n","        predictions[reg_name] = y_pred_test\n","\n","    lasso_pred = predictions['Lasso']\n","    lgbm_pred = predictions['LGBMRegressor']\n","    rf_pred = predictions['RandomForestRegressor']\n","    average_three = (lasso_pred + lgbm_pred + rf_pred) / 3\n","    average_lgbm_rf = (lgbm_pred+rf_pred) /2 \n","    average_lgbm_la = (lgbm_pred + lasso_pred) /2\n","    average_rf_la = (lasso_pred+rf_pred) / 2\n","\n","    result_test['y_pred_avg_three'] = average_three\n","    result_test['y_pred_avg_lgbm_rf'] = average_lgbm_rf\n","    result_test['y_pred_avg_lgbm_la'] = average_lgbm_la\n","    result_test['y_pred_avg_rf_la'] = average_rf_la\n","    \n","    scores_df = pd.DataFrame(scores).transpose()\n","\n","    # train, test 예측치 저장\n","    result_test.to_csv('prediction_results_test_set_day.csv', index=False, encoding=\"cp949\")\n","\n","    return scores_df\n","\n","scores_df = execute_pipeline(X_train, y_train, X_test, y_test)\n","print(scores_df)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### MAE 모델별 비교"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","# predict = pd.read_csv('prediction_results_test_set_day.csv', encoding = \"cp949\")\n","\n","# predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","# predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","# predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","# predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","\n","# predict['MAE_avg_three'] = abs(predict['y_pred_avg_three'] - predict['y_test'])\n","# predict['MAE_avg_lgbm_rf'] = abs(predict['y_pred_avg_lgbm_rf'] - predict['y_test'])\n","# predict['MAE_avg_lgbm_la'] = abs(predict['y_pred_avg_lgbm_la'] - predict['y_test'])\n","# predict['MAE_avg_rf_la'] = abs(predict['y_pred_avg_rf_la'] - predict['y_test'])\n","\n","\n","# result = predict.groupby(['holiday_yn']).agg({\n","#   'MAE_LinearRegression': np.mean,\n","#   'MAE_Lasso': np.mean,\n","#   'MAE_LGBMRegressor': np.mean,\n","#   'MAE_RandomForestRegressor': np.mean,\n","#   'MAE_avg_three' : np.mean,\n","#   'MAE_avg_lgbm_rf' : np.mean,\n","#   'MAE_avg_lgbm_la' : np.mean,\n","#   'MAE_avg_rf_la' : np.mean \n","# }).reset_index()\n","\n","# print(result)\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                       index           0\n","0       MAE_LinearRegression  614.769712\n","1                  MAE_Lasso  613.665010\n","2          MAE_LGBMRegressor  601.192139\n","3  MAE_RandomForestRegressor  631.095944\n","4              MAE_avg_three  575.734307\n","5            MAE_avg_lgbm_rf  607.011034\n","6            MAE_avg_lgbm_la  573.138024\n","7              MAE_avg_rf_la  577.539547\n"]}],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set_day.csv', encoding = \"cp949\")\n","\n","predict['MAE_LinearRegression'] = abs(predict['y_pred_test_LinearRegression'] - predict['y_test'])\n","predict['MAE_Lasso'] = abs(predict['y_pred_test_Lasso'] - predict['y_test'])\n","\n","predict['MAE_LGBMRegressor'] = abs(predict['y_pred_test_LGBMRegressor'] - predict['y_test'])\n","predict['MAE_RandomForestRegressor'] = abs(predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])\n","\n","predict['MAE_avg_three'] = abs(predict['y_pred_avg_three'] - predict['y_test'])\n","predict['MAE_avg_lgbm_rf'] = abs(predict['y_pred_avg_lgbm_rf'] - predict['y_test'])\n","predict['MAE_avg_lgbm_la'] = abs(predict['y_pred_avg_lgbm_la'] - predict['y_test'])\n","predict['MAE_avg_rf_la'] = abs(predict['y_pred_avg_rf_la'] - predict['y_test'])\n","\n","result = predict.agg({\n","  'MAE_LinearRegression': np.mean,\n","  'MAE_Lasso': np.mean,\n","  'MAE_LGBMRegressor': np.mean,\n","  'MAE_RandomForestRegressor': np.mean,\n","  'MAE_avg_three' : np.mean,\n","  'MAE_avg_lgbm_rf' : np.mean,\n","  'MAE_avg_lgbm_la' : np.mean,\n","  'MAE_avg_rf_la' : np.mean \n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### MAPE 모델별 비교"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                        index         0\n","0       MAPE_LinearRegression  3.741362\n","1                  MAPE_Lasso  3.734612\n","2          MAPE_LGBMRegressor  3.618362\n","3  MAPE_RandomForestRegressor  3.791393\n","4              MAPE_avg_three  3.471523\n","5            MAPE_avg_lgbm_rf  3.647380\n","6            MAPE_avg_lgbm_la  3.467944\n","7              MAPE_avg_rf_la  3.485911\n"]}],"source":["predict = pd.read_csv('prediction_results_test_set_day.csv', encoding = \"cp949\")\n","\n","predict['MAPE_LinearRegression'] = abs((predict['y_pred_test_LinearRegression'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_Lasso'] = abs((predict['y_pred_test_Lasso'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_LGBMRegressor'] = abs((predict['y_pred_test_LGBMRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_RandomForestRegressor'] = abs((predict['y_pred_test_RandomForestRegressor'] - predict['y_test']) / predict['y_test']) * 100\n","\n","predict['MAPE_avg_three'] = abs((predict['y_pred_avg_three'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_lgbm_rf'] = abs((predict['y_pred_avg_lgbm_rf'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_lgbm_la'] = abs((predict['y_pred_avg_lgbm_la'] - predict['y_test']) / predict['y_test']) * 100\n","predict['MAPE_avg_rf_la'] = abs((predict['y_pred_avg_rf_la'] - predict['y_test']) / predict['y_test']) * 100\n","\n","result = predict.agg({\n","    'MAPE_LinearRegression': np.mean,\n","    'MAPE_Lasso': np.mean,\n","    'MAPE_LGBMRegressor': np.mean,\n","    'MAPE_RandomForestRegressor': np.mean,\n","    'MAPE_avg_three' : np.mean,\n","    'MAPE_avg_lgbm_rf' : np.mean,\n","    'MAPE_avg_lgbm_la' : np.mean,\n","    'MAPE_avg_rf_la' : np.mean \n","}).reset_index()\n","\n","print(result)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### RMSE 모델 비교 "]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                                Model  MeanSquaredError        RMSE\n","0       SquaredError_LinearRegression     618655.576085  786.546614\n","1                  SquaredError_Lasso     616541.375473  785.201487\n","2          SquaredError_LGBMRegressor     626642.262371  791.607392\n","3  SquaredError_RandomForestRegressor     666090.464007  816.143654\n","4              SquaredError_avg_three     574619.664875  758.036717\n","5            SquaredError_avg_lgbm_rf     621279.276747  788.212710\n","6            SquaredError_avg_lgbm_la     572052.283672  756.341380\n","7              SquaredError_avg_rf_la     576881.211013  759.526965\n"]}],"source":["# 데이터 프레임에서 각 모델의 예측 값 - 실제 값 계산\n","predict = pd.read_csv('prediction_results_test_set_day.csv', encoding = \"cp949\")\n","\n","predict['SquaredError_LinearRegression'] = (predict['y_pred_test_LinearRegression'] - predict['y_test'])**2\n","predict['SquaredError_Lasso'] = (predict['y_pred_test_Lasso'] - predict['y_test'])**2\n","predict['SquaredError_LGBMRegressor'] = (predict['y_pred_test_LGBMRegressor'] - predict['y_test'])**2\n","predict['SquaredError_RandomForestRegressor'] = (predict['y_pred_test_RandomForestRegressor'] - predict['y_test'])**2\n","predict['SquaredError_avg_three'] = (predict['y_pred_avg_three'] - predict['y_test'])**2\n","predict['SquaredError_avg_lgbm_rf'] = (predict['y_pred_avg_lgbm_rf'] - predict['y_test'])**2\n","predict['SquaredError_avg_lgbm_la'] = (predict['y_pred_avg_lgbm_la'] - predict['y_test'])**2\n","predict['SquaredError_avg_rf_la'] = (predict['y_pred_avg_rf_la'] - predict['y_test'])**2\n","\n","# 차이의 제곱의 평균을 구한 후 제곱근 계산\n","mean_squared_errors = predict.agg({\n","  'SquaredError_LinearRegression': np.mean,\n","  'SquaredError_Lasso': np.mean,\n","  'SquaredError_LGBMRegressor': np.mean,\n","  'SquaredError_RandomForestRegressor': np.mean,\n","  'SquaredError_avg_three' : np.mean,\n","  'SquaredError_avg_lgbm_rf' : np.mean,\n","  'SquaredError_avg_lgbm_la' : np.mean,\n","  'SquaredError_avg_rf_la' : np.mean\n","}).reset_index()\n","\n","mean_squared_errors.columns = ['Model', 'MeanSquaredError']\n","\n","mean_squared_errors['RMSE'] = np.sqrt(mean_squared_errors['MeanSquaredError'])\n","\n","print(mean_squared_errors)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 변수 중요도 파악 "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### permutation importance -> RandomForest, LGBM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    # train set에 대한 permutation importance 계산\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","\n","    # test set에 대한 permutation importance 계산\n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    # importance 값 저장 (numpy array를 list로 변환)\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    # importance 값에 따라 내림차순 정렬\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","\n","    # CSV 파일로 저장\n","    feature_importances.to_csv('feature_importances_lgbm.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","# LGBM 모델을 불러옴\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","\n","# permutation importance 계산\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","#print(scores_df)\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# permutation importance \n","\n","def calculate_permutation_importance(model, X_train, y_train, X_test, y_test):\n","    perm_importance_train = permutation_importance(model, X_train, y_train, n_repeats=5, random_state=42)\n","    \n","    perm_importance_test = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42)\n","\n","    perm_importances_train = perm_importance_train.importances_mean.tolist()\n","    perm_importances_test = perm_importance_test.importances_mean.tolist()\n","\n","    # 특성명과 importance 값 매핑\n","    feature_importances = pd.DataFrame({\n","        'feature': X_train.columns,\n","        'perm_importance_train': perm_importances_train,\n","        'perm_importance_test': perm_importances_test,\n","    })\n","\n","    feature_importances = feature_importances.sort_values(by='perm_importance_train', ascending=False)\n","    \n","    feature_importances.to_csv('feature_importances_Rf.csv', index=False, encoding=\"cp949\")\n","    \n","    return feature_importances\n","\n","lgbm_model = joblib.load('model_RandomForestRegressor.joblib')\n","\n","feature_importances = calculate_permutation_importance(lgbm_model, X_train, y_train, X_test, y_test)\n","\n","print(feature_importances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lasso_model = joblib.load('model_Lasso.joblib')\n","lasso_coef = pd.Series(lasso_model.coef_, index=X_train.columns)\n","selected_feats_lasso = lasso_coef[lasso_coef!=0].index\n","\n","print(\"Number of features selected by Lasso: \", len(selected_feats_lasso))\n","print(\"Features selected by Lasso: \", selected_feats_lasso)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_feature_importances(model, model_name):\n","    importances = model.feature_importances_\n","    feat_names = X_train.columns\n","    feature_imp = pd.Series(importances, index=feat_names).sort_values(ascending=False)\n","\n","    #print(\"Feature importances for \", model_name, \" : \")\n","    #print(feature_imp)\n","\n","    # Creating a bar plot\n","    plt.figure(figsize = (20,15))\n","    sns.barplot(x=feature_imp, y=feature_imp.index)\n","    # Add labels to your graph\n","    plt.xlabel('Feature Importance Score')\n","    plt.ylabel('Features')\n","    plt.title(\"Visualizing Important Features\")\n","    plt.legend()\n","    plt.show()\n","\n","lgbm_model = joblib.load('model_LGBMRegressor.joblib')\n","plot_feature_importances(lgbm_model, 'LGBMRegressor')\n","\n","rf_model = joblib.load('model_RandomForestRegressor.joblib')\n","plot_feature_importances(rf_model, 'RandomForestRegressor')\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOkyqR2aUppxXzWFbfAgzsu","collapsed_sections":[],"mount_file_id":"1eUFPL5ZZ69p7pC4O-gceXVxX2nvWxp7E","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
